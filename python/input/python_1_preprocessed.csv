stratum,class,comment,Summary,Usage,Parameters,Expand,DevelopmentNotes
1,AccessMixin,"abstract cbv mixin that gives access mixins the same customizable
functionality.","abstract cbv mixin that gives access mixins the same customizable
functionality.",,,,
1,AmbiguityError,more than one migration matches a name prefix.,more than one migration matches a name prefix.,,,,
1,AppConfigStub,stub of an appconfig. only provides a label and a dict of models.,stub of an appconfig.,,only provides a label and a dict of models.,,
1,Archive,the external api class that encapsulates an archive implementation.,the external api class that encapsulates an archive implementation.,,,,the external api class that encapsulates an archive implementation.
1,ArchiveIndexView,top level archive of date based items.,top level archive of date based items.,,,,
1,Atomic,"guarantee the atomic execution of a given block.

an instance can be used either as a decorator or as a context manager.

when it s used as a decorator, call wraps the execution of the
decorated function in the instance itself, used as a context manager.

when it s used as a context manager, enter creates a transaction or a
savepoint, depending on whether a transaction is already in progress, and
exit commits the transaction or releases the savepoint on normal exit,
and rolls back the transaction or to the savepoint on exceptions.

it s possible to disable the creation of savepoints if the goal is to
ensure that some code runs within a transaction without creating overhead.

a stack of savepoints identifiers is maintained as an attribute of the
connection. none denotes the absence of a savepoint.

this allows reentrancy even if the same atomicwrapper is reused. for
example, it s possible to define oa atomic other and use @oa or
with oa multiple times.

since database connections are thread local, this is thread safe.

this is a private api.",guarantee the atomic execution of a given block.,"when it s used as a decorator, call wraps the execution of the
decorated function in the instance itself, used as a context manager.

when it s used as a context manager, enter creates a transaction or a
savepoint, depending on whether a transaction is already in progress, and
exit commits the transaction or releases the savepoint on normal exit,
and rolls back the transaction or to the savepoint on exceptions.

it s possible to disable the creation of savepoints if the goal is to
ensure that some code runs within a transaction without creating overhead.

a stack of savepoints identifiers is maintained as an attribute of the
connection. none denotes the absence of a savepoint.

this allows reentrancy even if the same atomicwrapper is reused.",,"an instance can be used either as a decorator or as a context manager.when it s used as a decorator, call wraps the execution of the
decorated function in the instance itself, used as a context manager.",
1,AtomicTests,"tests for the atomic decorator and context manager.

the tests make assertions on internal attributes because there isn t a
robust way to ask the database for its current transaction state.

since the decorator syntax is converted into a context manager see the
implementation , there are only a few basic tests with the decorator
syntax and the bulk of the tests use the context manager syntax.",tests for the atomic decorator and context manager.,,,"the tests make assertions on internal attributes because there isn t a
robust way to ask the database for its current transaction state.

since the decorator syntax is converted into a context manager see the
implementation , there are only a few basic tests with the decorator
syntax and the bulk of the tests use the context manager syntax.",
1,AutoFieldMeta,"metaclass to maintain backward inheritance compatibility for autofield.

it is intended that autofieldmixin become public api when it is possible to
create a non integer automatically generated field using column defaults
stored in the database.

in many areas django also relies on using isinstance to check for an
automatically generated field as a subclass of autofield. a new flag needs
to be implemented on field to be used instead.

when these issues have been addressed, this metaclass could be used to
deprecate inheritance from autofield and use of isinstance with autofield
for detecting automatically generated fields.",metaclass to maintain backward inheritance compatibility for autofield.,"in many areas django also relies on using isinstance to check for an
automatically generated field as a subclass of autofield. a new flag needs
to be implemented on field to be used instead.",,"it is intended that autofieldmixin become public api when it is possible to
create a non integer automatically generated field using column defaults
stored in the database.","when these issues have been addressed, this metaclass could be used to
deprecate inheritance from autofield and use of isinstance with autofield
for detecting automatically generated fields."
1,BadSignature,signature does not match.,signature does not match.,,,,
1,BarAccount,a service specific account of type bar.,a service specific account of type bar.,,,,
1,BaseCommand,"the base class from which all management commands ultimately
derive.

use this class if you want access to all of the mechanisms which
parse the command line arguments and work out what code to call in
response if you don t need to change any of that behavior,
consider using one of the subclasses defined in this file.

if you are interested in overriding customizing various aspects of
the command parsing and execution behavior, the normal flow works
as follows

1. django admin or manage.py loads the command class
and calls its run from argv method.

2. the run from argv method calls create parser to get
an argumentparser for the arguments, parses them, performs
any environment changes requested by options like
pythonpath , and then calls the execute method,
passing the parsed arguments.

3. the execute method attempts to carry out the command by
calling the handle method with the parsed arguments any
output produced by handle will be printed to standard
output and, if the command is intended to produce a block of
sql statements, will be wrapped in begin and commit .

4. if handle or execute raised any exception eg
commanderror , run from argv will instead print an error
message to stderr .

thus, the handle method is typically the starting point for
subclasses many built in commands and command types either place
all of their logic in handle , or perform some additional
parsing work in handle and then delegate from it to more
specialized methods as needed.

several attributes affect behavior at various steps along the way

help
a short description of the command, which will be printed in
help messages.

output transaction
a boolean indicating whether the command outputs sql
statements if true , the output will automatically be
wrapped with begin and commit . default value is
false .

requires migrations checks
a boolean if true , the command prints a warning if the set of
migrations on disk don t match the migrations in the database.

requires system checks
a boolean if true , entire django project will be checked for errors
prior to executing the command. default value is true .
to validate an individual application s models
rather than all applications models, call
self.check app configs from handle , where app configs
is the list of application s configuration provided by the
app registry.

stealth options
a tuple of any options the command uses which aren t defined by the
argument parser.","the base class from which all management commands ultimately
derive.","if you are interested in overriding customizing various aspects of
the command parsing and execution behavior, the normal flow works
as follows

1. django admin or manage.py loads the command class
and calls its run from argv method.

2. the run from argv method calls create parser to get
an argumentparser for the arguments, parses them, performs
any environment changes requested by options like
pythonpath , and then calls the execute method,
passing the parsed arguments.

3. the execute method attempts to carry out the command by
calling the handle method with the parsed arguments any
output produced by handle will be printed to standard
output and, if the command is intended to produce a block of
sql statements, will be wrapped in begin and commit .

4. if handle or execute raised any exception eg
commanderror , run from argv will instead print an error
message to stderr .","several attributes affect behavior at various steps along the way

help
a short description of the command, which will be printed in
help messages.

output transaction
a boolean indicating whether the command outputs sql
statements if true , the output will automatically be
wrapped with begin and commit . default value is
false .

requires migrations checks
a boolean if true , the command prints a warning if the set of
migrations on disk don t match the migrations in the database.

requires system checks
a boolean if true , entire django project will be checked for errors
prior to executing the command. default value is true .
to validate an individual application s models
rather than all applications models, call
self.check app configs from handle , where app configs
is the list of application s configuration provided by the
app registry.",,"use this class if you want access to all of the mechanisms which
parse the command line arguments and work out what code to call in
response if you don t need to change any of that behavior,
consider using one of the subclasses defined in this file.

thus, the handle method is typically the starting point for
subclasses many built in commands and command types either place
all of their logic in handle , or perform some additional
parsing work in handle and then delegate from it to more
specialized methods as needed."
1,BaseDatabaseSchemaEditor,"this class and its subclasses are responsible for emitting schema changing
statements to the databases model creation removal alteration, field
renaming, index fiddling, and so on.","this class and its subclasses are responsible for emitting schema changing
statements to the databases model creation removal alteration, field
renaming, index fiddling, and so on.",,,,"this class and its subclasses are responsible for emitting schema changing
statements to the databases model creation removal alteration, field
renaming, index fiddling, and so on."
1,BaseExpression,base class for all query expressions.,base class for all query expressions.,,,,
1,BaseUpdateView,"base view for updating an existing object.

using this base class requires subclassing to provide a response mixin.",base view for updating an existing object.,,,,using this base class requires subclassing to provide a response mixin.
1,BaseYearArchiveView,list of objects published in a given year.,list of objects published in a given year.,,,,
1,BCryptSHA256PasswordHasher,"secure password hashing using the bcrypt algorithm recommended

this is considered by many to be the most secure algorithm but you
must first install the bcrypt library. please be warned that
this library depends on native c code and might cause portability
issues.",secure password hashing using the bcrypt algorithm recommended,"this is considered by many to be the most secure algorithm but you
must first install the bcrypt library.",,,
1,BoundWidget,"a container class used for iterating over widgets. this is useful for
widgets that have choices. for example, the following can be used in a
template

% for radio in myform.beatles %
label for radio.id for label
radio.choice label
span class radio radio.tag span
label
% endfor %",a container class used for iterating over widgets.,"for example, the following can be used in a
template

% for radio in myform.beatles %
label for radio.id for label
radio.choice label
span class radio radio.tag span
label
% endfor %",,,"this is useful for
widgets that have choices."
1,CacheHandler,"a cache handler to manage access to cache instances.

ensure only one instance of each alias exists per thread.",a cache handler to manage access to cache instances.,,,ensure only one instance of each alias exists per thread.,
1,Choices,class for creating enumerated choices.,class for creating enumerated choices.,,class for creating enumerated choices.,,
1,ChunkIter,"an iterable that will yield chunks of data. given a file like object as the
constructor, yield chunks of read operations from that object.",an iterable that will yield chunks of data.,,,"given a file like object as the
constructor, yield chunks of read operations from that object.",
1,Client,"a class that can act as a client for testing purposes.

it allows the user to compose get and post requests, and
obtain the response that the server gave to those requests.
the server response objects are annotated with the details
of the contexts and templates that were rendered during the
process of serving the request.

client objects are stateful they will retain cookie and
thus session details for the lifetime of the client instance.

this is not intended as a replacement for twill selenium or
the like it is here to allow testing against the
contexts and templates produced by a view, rather than the
html rendered to the end user.",a class that can act as a client for testing purposes.,,,"it allows the user to compose get and post requests, and
obtain the response that the server gave to those requests.
the server response objects are annotated with the details
of the contexts and templates that were rendered during the
process of serving the request.

client objects are stateful they will retain cookie and
thus session details for the lifetime of the client instance.","this is not intended as a replacement for twill selenium or
the like it is here to allow testing against the
contexts and templates produced by a view, rather than the
html rendered to the end user."
1,Combinable,"provide the ability to combine one or two objects with
some connector. for example f foo f bar .","provide the ability to combine one or two objects with
some connector.",for example f foo f bar .,,,
1,ConsoleDirective,"a restructuredtext directive which renders a two tab code block in which
the second tab shows a windows command line equivalent of the usual
unix oriented examples.","a restructuredtext directive which renders a two tab code block in which
the second tab shows a windows command line equivalent of the usual
unix oriented examples.",,,,
1,Context,a stack container for variable context,a stack container for variable context,,,,
1,CryptPasswordHasher,"password hashing using unix crypt not recommended

the crypt module is not supported on all platforms.",password hashing using unix crypt not recommended,,,,the crypt module is not supported on all platforms.
1,CustomArticleAdmin,tests various hooks for using custom templates and contexts.,tests various hooks for using custom templates and contexts.,,,,
1,CustomCacheKeyValidationTests,"tests for the ability to mixin a custom validate key method to
a custom cache backend that otherwise inherits from a builtin
backend, and override the default key validation. refs #6447.","tests for the ability to mixin a custom validate key method to
a custom cache backend",,,"that otherwise inherits from a builtin
backend, and override the default key validation.",
1,CustomHeaderRemoteUserTest,"tests a custom remoteusermiddleware subclass with custom http auth user
header.",tests a custom remoteusermiddleware subclass,,tests a custom remoteusermiddleware subclass with custom http auth user,,
1,DatabaseReceiver,used in the tests for the database argument in signals #13552,used in the tests for the database argument in signals #13552,,,,
1,DblFromGeom,"argument is a geometry, return type is double that is passed
in by reference as the last argument.",,,"argument is a geometry,

return type is double that is passed
in by reference as the last argument",,
1,DisallowedModelAdminToField,invalid to field was passed to admin view via url query string,invalid to field was passed to admin view via url query string,,,,
1,DjangoHTMLTranslator,django specific rest to html tweaks.,django specific rest to html tweaks.,,,,
1,Dumpdata,tests for dumpdata management command.,tests for dumpdata management command.,,,,
1,EarliestOrLatestTests,tests for the earliest and latest objects methods,tests for the earliest and latest objects methods,,,,
1,EmptyStringsAsNullTest,"filtering on non null character fields works as expected.
the reason for these tests is that oracle treats as null, and this
can cause problems in query construction. refs #17957.",,,,,
1,ErrorDict,"a collection of errors that knows how to display itself in various formats.

the dictionary keys are the field names, and the values are the errors.",a collection of errors that knows how to display itself in various formats.,"the dictionary keys are the field names, and the values are the errors.",,,
1,ExceptionThatFailsUnpickling,"after pickling, this class fails unpickling with an error about incorrect
arguments passed to init .","after pickling, this class fails unpickling with an error about incorrect
arguments passed to init .",,,,
1,FakePayload,"a wrapper around bytesio that restricts what can be read since data from
the network can t be sought and cannot be read outside of its content
length. this makes sure that views can t do anything under the test client
that wouldn t work in real life.","a wrapper around bytesio that restricts what can be read since data from
the network can t be sought and cannot be read outside of its content
length.",,,"this makes sure that views can t do anything under the test client
that wouldn t work in real life.",
1,FallbackStorage,"try to store all messages in the first backend. store any unstored
messages in each subsequent backend.",,,,"try to store all messages in the first backend. store any unstored
messages in each subsequent backend.",
1,FootNote,model added for ticket 19838,,,,,model added for ticket 19838
1,FrenchTestCase,tests using the french translations of the sampleproject.,tests using the french translations of the sampleproject.,,,,
1,GeoFlexibleFieldLookupDict,"subclass that includes updates the base data types reverse dict
for geometry field types.",,,,,
1,Group,table column fields,table column fields,,,,
1,GZipMiddleware,"compress content if the browser allows gzip compression.
set the vary header accordingly, so that caches will base their storage
on the accept encoding header.","compress content if the browser allows gzip compression.set the vary header accordingly, so that caches will base their storage
on the accept encoding header.",,,,
1,HiddenRangeWidget,a widget that splits input into two input type hidden inputs.,a widget that splits input into two input type hidden inputs.,,,,
1,ImageFileDescriptor,"just like the filedescriptor, but for imagefields. the only difference is
assigning the width height to the width field height field, if appropriate.","just like the filedescriptor, but for imagefields.",,,"the only difference is
assigning the width height to the width field height field, if appropriate.",
1,IncompleteCategoryFormWithExclude,"a form that replaces the model s url field with a custom one. this should
prevent the model field s validation from being called.",a form that replaces the model s url field with a custom one.,,,,
1,Individual,"a model with a fk to itself. it won t be registered with the admin, so the
corresponding raw id widget won t have a magnifying glass link to select
related instances rendering will be called programmatically in this case .",a model with a fk to itself.,"it won t be registered with the admin, so the
corresponding raw id widget won t have a magnifying glass link to select
related instances rendering will be called programmatically in this case .",,,"it won t be registered with the admin, so the
corresponding raw id widget won t have a magnifying glass link to select
related instances rendering will be called programmatically in this case ."
1,InputStreamExhausted,no more reads are allowed from this device.,no more reads are allowed from this device.,,,no more reads are allowed from this device.,
1,IntFromGeom,"argument is a geometry, return type is an integer.",,,"argument is a geometry, return type is an integer.",,"argument is a geometry, return type is an integer."
1,InvalidBasesError,a model s base classes can t be resolved.,a model s base classes can t be resolved.,,,,
1,KMLSitemap,a minimal hook to produce kml sitemaps.,a minimal hook to produce kml sitemaps.,,,,
1,ListMixin,"a base class which provides complete list interface.
derived classes must call listmixin s init function
and implement the following

function get single external self, i
return single item with index i for general use.
the index i will always satisfy 0 i len self .

function get single internal self, i
same as above, but for use within the class optional
note that if get single internal and get single internal return
different types of objects, set list must distinguish
between the two and handle each appropriately.

function set list self, length, items
recreate the entire object.

note items may be a generator which calls get single internal.
therefore, it is necessary to cache the values in a temporary
temp list items
before clobbering the original storage.

function set single self, i, value
set the single item at index i to value optional
if left undefined, all mutations will result in rebuilding
the object using set list.

function len self
return the length

int minlength
the minimum legal length optional

int maxlength
the maximum legal length optional

type or tuple allowed
a type or tuple of allowed item types optional",a base class which provides complete list interface.,,,"derived classes must call listmixin s init function
and implement the following

function get single external self, i
return single item with index i for general use.
the index i will always satisfy 0 i len self .

function get single internal self, i
same as above, but for use within the class optional
note that if get single internal and get single internal return
different types of objects, set list must distinguish
between the two and handle each appropriately.

function set list self, length, items
recreate the entire object.

note items may be a generator which calls get single internal.
therefore, it is necessary to cache the values in a temporary
temp list items
before clobbering the original storage.

function set single self, i, value
set the single item at index i to value optional
if left undefined, all mutations will result in rebuilding
the object using set list.

function len self
return the length

int minlength
the minimum legal length optional

int maxlength
the maximum legal length optional

type or tuple allowed
a type or tuple of allowed item types optional",
1,LogoutThenLoginTests,tests for the logout then login view,tests for the logout then login view,,,,
1,MakeListTests,"the make list filter can destroy existing escaping, so the results are
escaped.",,,,"the make list filter can destroy existing escaping, so the results are
escaped.",
1,ManagementForm,"keep track of how many form instances are displayed on the page. if adding
new forms via javascript, you should increment the count field of this form
as well.",keep track of how many form instances are displayed on the page.,,,,
1,MemcachedCache,an implementation of a cache binding using python memcached,an implementation of a cache binding using python memcached,,,,
1,MemoryFileUploadHandler,file upload handler to stream uploads into memory used for small files .,file upload handler to stream uploads into memory used for small files .,,,,
1,Migration,"the base class for all migrations.

migration files will import this from django.db.migrations.migration
and subclass it as a class called migration. it will have one or more
of the following attributes

operations a list of operation instances, probably from django.db.migrations.operations
dependencies a list of tuples of app path, migration name
run before a list of tuples of app path, migration name
replaces a list of migration names

note that all migrations come out of migrations and into the loader or
graph as instances, having been initialized with their app label and name.",the base class for all migrations.,"it will have one or more
of the following attributes

operations a list of operation instances, probably from django.db.migrations.operations
dependencies a list of tuples of app path, migration name
run before a list of tuples of app path, migration name
replaces a list of migration names","it will have one or more
of the following attributes

operations a list of operation instances, probably from django.db.migrations.operations
dependencies a list of tuples of app path, migration name
run before a list of tuples of app path, migration name
replaces a list of migration names",,
1,MigrationGraph,"represent the digraph of all migrations in a project.

each migration is a node, and each dependency is an edge. there are
no implicit dependencies between numbered migrations the numbering is
merely a convention to aid file listing. every new numbered migration
has a declared dependency to the previous number, meaning that vcs
branch merges can be detected and resolved.

migrations files can be marked as replacing another set of migrations
this is to support the squash feature. the graph handler isn t responsible
for these instead, the code to load them in here should examine the
migration files and if the replaced migrations are all either unapplied
or not present, it should ignore the replaced ones, load in just the
replacing migration, and repoint any dependencies that pointed to the
replaced migrations to point to the replacing one.

a node should be a tuple app path, migration name . the tree special cases
things within an app namely, root nodes and leaf nodes ignore dependencies
to other apps.",represent the digraph of all migrations in a project.,"migrations files can be marked as replacing another set of migrations
this is to support the squash feature.

the graph handler isn t responsible
for these instead, the code to load them in here should examine the
migration files and if the replaced migrations are all either unapplied
or not present, it should ignore the replaced ones, load in just the
replacing migration, and repoint any dependencies that pointed to the
replaced migrations to point to the replacing one.","a node should be a tuple app path, migration name .",,"each migration is a node, and each dependency is an edge.

there are
no implicit dependencies between numbered migrations the numbering is
merely a convention to aid file listing."
1,MigrationLoader,"load migration files from disk and their status from the database.

migration files are expected to live in the migrations directory of
an app. their names are entirely unimportant from a code perspective,
but will probably follow the 1234 name.py convention.

on initialization, this class will scan those directories, and open and
read the python files, looking for a class called migration, which should
inherit from django.db.migrations.migration. see
django.db.migrations.migration for what that looks like.

some migrations will be marked as replacing another set of migrations.
these are loaded into a separate set of migrations away from the main ones.
if all the migrations they replace are either unapplied or missing from
disk, then they are injected into the main set, replacing the named migrations.
any dependency pointers to the replaced migrations are re pointed to the
new migration.

this does mean that this class must also talk to the database as well as
to disk, but this is probably fine. we re already not just operating
in memory.",load migration files from disk and their status from the database.,"this does mean that this class must also talk to the database as well as
to disk, but this is probably fine. we re already not just operating
in memory.",,"on initialization, this class will scan those directories, and open and
read the python files, looking for a class called migration, which should
inherit from django.db.migrations.migration. see
django.db.migrations.migration for what that looks like.

some migrations will be marked as replacing another set of migrations.
these are loaded into a separate set of migrations away from the main ones.
if all the migrations they replace are either unapplied or missing from
disk, then they are injected into the main set, replacing the named migrations.
any dependency pointers to the replaced migrations are re pointed to the
new migration.",
1,MigrationQuestioner,"give the autodetector responses to questions it might have.
this base class has a built in noninteractive mode, but the
interactive subclass is what the command line arguments will use.",give the autodetector responses to questions it might have.,"this base class has a built in noninteractive mode, but the
interactive subclass is what the command line arguments will use.",,,"this base class has a built in noninteractive mode, but the
interactive subclass is what the command line arguments will use."
1,MigrationWriter,"take a migration instance and is able to produce the contents
of the migration file from it.","take a migration instance and is able to produce the contents
of the migration file from it.",,,,
1,ModelBase,metaclass for all models.,metaclass for all models.,,,,
1,ModelSignal,"signal subclass that allows the sender to be lazily specified as a string
of the app label.modelname form.","signal subclass that allows the sender to be lazily specified as a string
of the app label.modelname form.",,,,
1,MultiPartParser,"a rfc2388 multipart form data parser.

multivaluedict.parse reads the input stream in chunk size chunks
and returns a tuple of multivaluedict post , multivaluedict files .",a rfc2388 multipart form data parser.,,,,"multivaluedict.parse reads the input stream in chunk size chunks
and returns a tuple of multivaluedict post , multivaluedict files ."
1,MultiValueDict,"a subclass of dictionary customized to handle multiple values for the
same key.

d multivaluedict name adrian , simon , position developer
d name
simon
d.getlist name
adrian , simon
d.getlist doesnotexist

d.getlist doesnotexist , adrian , simon
adrian , simon
d.get lastname , nonexistent
nonexistent
d.setlist lastname , holovaty , willison

this class exists to solve the irritating problem raised by cgi.parse qs,
which returns a list for every key, even though most web forms submit
single name value pairs.","a subclass of dictionary customized to handle multiple values for the
same key.","d multivaluedict name adrian , simon , position developer
d name
simon
d.getlist name
adrian , simon
d.getlist doesnotexist

d.getlist doesnotexist , adrian , simon
adrian , simon
d.get lastname , nonexistent
nonexistent
d.setlist lastname , holovaty , willison",,"this class exists to solve the irritating problem raised by cgi.parse qs,
which returns a list for every key, even though most web forms submit
single name value pairs.","this class exists to solve the irritating problem raised by cgi.parse qs,
which returns a list for every key, even though most web forms submit
single name value pairs."
1,MultiValueField,"aggregate the logic of multiple fields.

its clean method takes a decompressed list of values, which are then
cleaned into a single value according to self.fields. each value in
this list is cleaned by the corresponding field the first value is
cleaned by the first field, the second value is cleaned by the second
field, etc once all fields are cleaned, the list of clean values is
compressed into a single value.

subclasses should not have to implement clean . instead, they must
implement compress , which takes a list of valid values and returns a
compressed version of those values a single value.

you ll probably want to use this with multiwidget.",aggregate the logic of multiple fields.,,,"its clean method takes a decompressed list of values, which are then
cleaned into a single value according to self.fields. each value in
this list is cleaned by the corresponding field the first value is
cleaned by the first field, the second value is cleaned by the second
field, etc once all fields are cleaned, the list of clean values is
compressed into a single value.",
1,MultiWidget,"a widget that is composed of multiple widgets.

in addition to the values added by widget.get context , this widget
adds a list of subwidgets to the context as widget subwidgets .
these can be looped over and rendered like normal widgets.

you ll probably want to use this class with multivaluefield.",a widget that is composed of multiple widgets.,,,"in addition to the values added by widget.get context , this widget
adds a list of subwidgets to the context as widget subwidgets .
these can be looped over and rendered like normal widgets.",
1,MyModel,model subclass with a custom base using metaclass.,model subclass with a custom base using metaclass.,,,,
1,NestedObjectsTests,tests for nestedobject utility collection.,tests for nestedobject utility collection.,,,,
1,Operation,"base class for migration operations.

it s responsible for both mutating the in memory model state
see db migrations state.py to represent what it performs, as well
as actually performing it against a live database.

note that some operations won t modify memory state at all eg data
copying operations , and some will need their modifications to be
optionally specified by the user eg custom python code snippets

due to the way this class deals with deconstruction, it should be
considered immutable.",base class for migration operations.,,,"it s responsible for both mutating the in memory model state
see db migrations state.py to represent what it performs, as well
as actually performing it against a live database.",
1,OverwritingStorage,"overwrite existing files instead of appending a suffix to generate an
unused name.","overwrite existing files instead of appending a suffix to generate an
unused name.",,,,
1,ParentWithDependentChildren,"issue #20522
model where the validation of child foreign key relationships depends
on validation of the parent","model where the validation of child foreign key relationships depends
on validation of the parent",,,,
1,Permission,"the permissions system provides a way to assign permissions to specific
users and groups of users.

the permission system is used by the django admin site, but may also be
useful in your own code. the django admin site uses permissions as follows

the add permission limits the user s ability to view the add form
and add an object.
the change permission limits a user s ability to view the change
list, view the change form and change an object.
the delete permission limits the ability to delete an object.
the view permission limits the ability to view an object.

permissions are set globally per type of object, not per specific object
instance. it is possible to say mary may change news stories, but it s
not currently possible to say mary may change news stories, but only the
ones she created herself or mary may only change news stories that have a
certain status or publication date.

the permissions listed above are automatically created for each model.","the permissions system provides a way to assign permissions to specific
users and groups of users.","the permission system is used by the django admin site, but may also be
useful in your own code. the django admin site uses permissions as follows

the add permission limits the user s ability to view the add form
and add an object.
the change permission limits a user s ability to view the change
list, view the change form and change an object.
the delete permission limits the ability to delete an object.
the view permission limits the ability to view an object.",,the permissions listed above are automatically created for each model.,
1,PermissionDeniedBackendTest,other backends are not checked once a backend raises permissiondenied,,,,,
1,PrePopulatedPostLargeSlug,"regression test for #15938 a large max length for the slugfield must not
be localized in prepopulated fields js.html or it might end up breaking
the javascript ie, using thousand separator ends up with maxlength 1,000",,,,,
1,ProxyModelInheritanceTests,"proxy model inheritance across apps can result in migrate not creating the table
for the proxied model as described in #12286 . this test creates two dummy
apps and calls migrate, then verifies that the table has been created.","proxy model inheritance across apps can result in migrate not creating the table
for the proxied model as described in #12286 .",,,"this test creates two dummy
apps and calls migrate, then verifies that the table has been created.",
1,RawPostDataException,"you cannot access raw post data from a request that has
multipart post data if it has been accessed via post,
files, etc..","you cannot access raw post data from a request that has
multipart post data if it has been accessed via post,
files, etc..",,,"if it has been accessed via post,
files, etc..",
1,RemoteTestRunner,"run tests and record everything but don t display anything.

the implementation matches the unpythonic coding style of unittest2.",run tests and record everything but don t display anything.,,,,
1,RequestFactoryEnvironmentTests,"regression tests for #8551 and #17067 ensure that environment variables
are set correctly in requestfactory.","regression tests for #8551 and #17067 ensure that environment variables
are set correctly in requestfactory.",,,"ensure that environment variables
are set correctly in requestfactory.",
1,ReverseGenericManyToOneDescriptor,"accessor to the related objects manager on the one to many relation created
by genericrelation.

in the example

class post model
comments genericrelation comment

post.comments is a reversegenericmanytoonedescriptor instance.","accessor to the related objects manager on the one to many relation created
by genericrelation.","in the example

class post model
comments genericrelation comment

post.comments is a reversegenericmanytoonedescriptor instance.",,,
1,SameAsLookup,"the operator is the same as operator. it tests actual geometric
equality of two features. so if a and b are the same feature,
vertex by vertex, the operator returns true.","the operator is the same as operator. it tests actual geometric
equality of two features. so if a and b are the same feature,
vertex by vertex, the operator returns true.",,,"the operator is the same as operator. it tests actual geometric
equality of two features. so if a and b are the same feature,
vertex by vertex, the operator returns true.",
1,Serializer,convert a queryset to json.,convert a queryset to json.,,,,
1,SessionStorage,"store messages in the session that is, django.contrib.sessions .","store messages in the session that is, django.contrib.sessions .",,,,
1,SessionStore,"a database session store, that handles updating the account id column
inside the custom session model.","a database session store,",,,"that handles updating the account id column
inside the custom session model.",
1,SimpleView,a simple view with a docstring.,a simple view with a docstring.,,,,
1,SpatialRefSysMixin,"the spatialrefsysmixin is a class used by the database dependent
spatialrefsys objects to reduce redundant code.","the spatialrefsysmixin is a class used by the database dependent
spatialrefsys objects to reduce redundant code.",,,,"the spatialrefsysmixin is a class used by the database dependent
spatialrefsys objects to reduce redundant code."
1,SplitHiddenDateTimeWidget,a widget that splits datetime input into two input type hidden inputs.,a widget that splits datetime input into two input type hidden inputs.,,,,
1,StaticFilesHandler,"wsgi middleware that intercepts calls to the static files directory, as
defined by the static url setting, and serves those files.","wsgi middleware that intercepts calls to the static files directory, as
defined by the static url setting, and serves those files.",,"wsgi middleware that intercepts calls to the static files directory, as
defined by the static url setting, and serves those files.",,
1,StrictAssignmentTests,"should a model do anything special with setattr or descriptors which
raise a validationerror, a model form should catch the error #24706 .",,,,,
1,SubCategoryForm,"subclassing without specifying a meta on the class will use
the parent s meta or the first parent in the mro if there are
multiple parent classes .",,,,,
1,SuccessMessageMixin,add a success message on successful form submission.,add a success message on successful form submission.,,,,
1,TemplateDoesNotExist,"the exception used when a template does not exist. optional arguments

backend
the template backend class used when raising this exception.

tried
a list of sources that were tried when finding the template. this
is formatted as a list of tuples containing origin, status , where
origin is an origin object or duck type and status is a string with the
reason the template wasn t found.

chain
a list of intermediate templatedoesnotexist exceptions. this is used to
encapsulate multiple exceptions when loading templates from multiple
engines.",the exception used when a template does not exist,,"optional arguments

backend
the template backend class used when raising this exception.

tried
a list of sources that were tried when finding the template. this
is formatted as a list of tuples containing origin, status , where
origin is an origin object or duck type and status is a string with the
reason the template wasn t found.

chain
a list of intermediate templatedoesnotexist exceptions. this is used to
encapsulate multiple exceptions when loading templates from multiple
engines.",,
1,TestImageFieldFile,"custom field file class that records whether or not the underlying file
was opened.","custom field file class that records whether or not the underlying file
was opened.",,,,
1,TestRouter,routes to the other database if the model name starts with other .,,,,routes to the other database if the model name starts with other .,
1,TestUtils,"this doc output is required for testing. i copied this example from
admindocs documentation. title

display an individual model myapp.mymodel .

context

requestcontext

mymodel
an instance of model myapp.mymodel .

template

template myapp my template.html description

some metadata some data",,,,,this doc output is required for testing.
1,UniqueAnchor,"this is a model that can be used as
something for other models to point at","this is a model that can be used as
something for other models to point at",,,,
1,UpdateError,occurs if django tries to update a session that was deleted.,occurs if django tries to update a session that was deleted.,,,,
1,UserCreationForm,"a form that creates a user, with no privileges, from the given username and
password.","a form that creates a user, with no privileges, from the given username and
password.",,"a form that creates a user, with no privileges, from the given username and
password.",,
1,VariableWrapper,"an adapter class for cursor variables that prevents the wrapped object
from being converted into a string when used to instantiate an oracleparam.
this can be used generally for any other object that should be passed into
cursor.execute as is.","an adapter class for cursor variables that prevents the wrapped object
from being converted into a string when used to instantiate an oracleparam.","this can be used generally for any other object that should be passed into
cursor.execute as is.",,,
1,WindowFrame,"model the frame clause in window expressions. there are two types of frame
clauses which are subclasses, however, all processing and validation by no
means intended to be complete is done here. thus, providing an end for a
frame is optional the default is unbounded following, which is the last
row in the frame .",model the frame clause in window expressions,,,"there are two types of frame
clauses which are subclasses, however, all processing and validation by no
means intended to be complete is done here.",
1,XFrameOptionsDecoratorsTests,tests for the x frame options decorators.,tests for the x frame options decorators.,,,,
1,XFrameOptionsMiddleware,"set the x frame options http header in http responses.

do not set the header if it s already set or if the response contains
a xframe options exempt value set to true.

by default, set the x frame options header to sameorigin , meaning the
response can only be loaded on a frame within the same site. to prevent the
response from being loaded in a frame in any site, set x frame options in
your project s django settings to deny .",,"by default, set the x frame options header to sameorigin , meaning the
response can only be loaded on a frame within the same site.

to prevent the
response from being loaded in a frame in any site, set x frame options in
your project s django settings to deny .",,,"do not set the header if it s already set or if the response contains
a xframe options exempt value set to true.

by default, set the x frame options header to sameorigin , meaning the
response can only be loaded on a frame within the same site.

to prevent the
response from being loaded in a frame in any site, set x frame options in
your project s django settings to deny ."
2,Audio,"create an audio object.

when this object is returned by an input cell or passed to the
display function, it will result in audio controls being displayed
in the frontend only works in the notebook .

parameters

data numpy array, list, unicode, str or bytes
can be one of

numpy 1d array containing the desired waveform mono
numpy 2d array containing waveforms for each channel.
shape nchan, nsamples . for the standard channel order, see
http msdn.microsoft.com en us library windows hardware dn653308 v vs.85 .aspx
list of float or integer representing the waveform mono
string containing the filename
bytestring containing raw pcm data or
url pointing to a file on the web.

if the array option is used, the waveform will be normalized.

if a filename or url is used, the format support will be browser
dependent.
url unicode
a url to download the data from.
filename unicode
path to a local file to load the data from.
embed boolean
should the audio data be embedded using a data uri true or should
the original source be referenced. set this to true if you want the
audio to playable later with no internet connection in the notebook.

default is true , unless the keyword argument url is set, then
default value is false .
rate integer
the sampling rate of the raw data.
only required when data parameter is being used as an array
autoplay bool
set to true if the audio should immediately start playing.
default is false .
normalize bool
whether audio should be normalized rescaled to the maximum possible
range. default is true . when set to false , data must be between
1 and 1 inclusive , otherwise an error is raised.
applies only when data is a list or array of samples other types of
audio are never normalized.

examples

# generate a sound
import numpy as np
framerate 44100
t np.linspace 0,5,framerate 5
data np.sin 2 np.pi 220 t np.sin 2 np.pi 224 t
audio data,rate framerate

# can also do stereo or more channels
dataleft np.sin 2 np.pi 220 t
dataright np.sin 2 np.pi 224 t
audio dataleft, dataright ,rate framerate

audio http www.nch.com.au acm 8k16bitpcm.wav # from url
audio url http www.w3schools.com html horse.ogg

audio path to sound.wav # from file
audio filename path to sound.ogg

audio b raw wav data.. # from bytes
audio data b raw wav data..

see also

see also the audio widgets form the ipywidget package for more flexibility and options.",create an audio object.,"examples

# generate a sound
import numpy as np
framerate 44100
t np.linspace 0,5,framerate 5
data np.sin 2 np.pi 220 t np.sin 2 np.pi 224 t
audio data,rate framerate

# can also do stereo or more channels
dataleft np.sin 2 np.pi 220 t
dataright np.sin 2 np.pi 224 t
audio dataleft, dataright ,rate framerate

audio http www.nch.com.au acm 8k16bitpcm.wav # from url
audio url http www.w3schools.com html horse.ogg

audio path to sound.wav # from file
audio filename path to sound.ogg

audio b raw wav data.. # from bytes
audio data b raw wav data..","parameters

data numpy array, list, unicode, str or bytes
can be one of

numpy 1d array containing the desired waveform mono
numpy 2d array containing waveforms for each channel.
shape nchan, nsamples . for the standard channel order, see
http msdn.microsoft.com en us library windows hardware dn653308 v vs.85 .aspx
list of float or integer representing the waveform mono
string containing the filename
bytestring containing raw pcm data or
url pointing to a file on the web.

if the array option is used, the waveform will be normalized.

if a filename or url is used, the format support will be browser
dependent.
url unicode
a url to download the data from.
filename unicode
path to a local file to load the data from.
embed boolean
should the audio data be embedded using a data uri true or should
the original source be referenced. set this to true if you want the
audio to playable later with no internet connection in the notebook.

default is true , unless the keyword argument url is set, then
default value is false .
rate integer
the sampling rate of the raw data.
only required when data parameter is being used as an array
autoplay bool
set to true if the audio should immediately start playing.
default is false .
normalize bool
whether audio should be normalized rescaled to the maximum possible
range. default is true . when set to false , data must be between
1 and 1 inclusive , otherwise an error is raised.
applies only when data is a list or array of samples other types of
audio are never normalized.","when this object is returned by an input cell or passed to the
display function, it will result in audio controls being displayed
in the frontend only works in the notebook .",
2,capture_output,context manager for capturing stdout err,context manager for capturing stdout err,,,,
2,CapturingDisplayPublisher,a displaypublisher that store,a displaypublisher that store,,,,
2,CellMagicRole,cross reference role displayed with a %% prefix,cross reference role displayed with a %% prefix,,,,
2,DisplayHook,"the custom ipython displayhook to replace sys.displayhook.

this class does many things, but the basic idea is that it is a callable
that gets called anytime user code returns a value.",the custom ipython displayhook to replace sys.displayhook.,,,"this class does many things, but the basic idea is that it is a callable
that gets called anytime user code returns a value.",
2,DummyMod,"a dummy module used for ipython s interactive module when
a namespace must be assigned to the module s dict .","a dummy module used for ipython s interactive module when
a namespace must be assigned to the module s dict .",,,,
2,GeoJSON,"geojson expects json able dict

not an already serialized json string.

scalar types none, number, string are not allowed, only dict containers.",geojson expects json able dict,,,,"not an already serialized json string.

scalar types none, number, string are not allowed, only dict containers."
2,HelpEnd,transformer for help syntax obj? and obj??,transformer for help syntax obj? and obj??,,,,
2,HistoryAccessor,"access the history database without adding to it.

this is intended for use by standalone history tools. ipython shells use
historymanager, below, which is a subclass of this.",access the history database without adding to it.,"this is intended for use by standalone history tools. ipython shells use
historymanager, below, which is a subclass of this.",,,
2,InteractiveShellApp,"a mixin for applications that start interactiveshell instances.

provides configurables for loading extensions and executing files
as part of configuring a shell environment.

the following methods should be called by the meth initialize method
of the subclass

meth init path
meth init shell to be implemented by the subclass
meth init gui pylab
meth init extensions
meth init code","a mixin for applications that start interactiveshell instances.provides configurables for loading extensions and executing files
as part of configuring a shell environment.",,,"the following methods should be called by the meth initialize method
of the subclass

meth init path
meth init shell to be implemented by the subclass
meth init gui pylab
meth init extensions
meth init code",
2,IPythonInputSplitter,an input splitter that recognizes all of ipython s special syntax.,an input splitter that recognizes all of ipython s special syntax.,,,,
2,LazyEvaluate,"this is used for formatting strings with values that need to be updated
at that time, such as the current time or working directory.",,,,,"this is used for formatting strings with values that need to be updated
at that time, such as the current time or working directory."
2,Magics,"base class for implementing magic functions.

shell functions which can be reached as %function name. all magic
functions should accept a string, which they can parse for their own
needs. this can make some functions easier to type, eg%cd ..
vs. %cd ..

classes providing magic functions need to subclass this class, and they
must

use the method decorators @line magic and @cell magic to decorate
individual methods as magic functions, and

use the class decorator @magics class to ensure that the magic
methods are properly registered at the instance level upon instance
initialization.

see mod magic functions for examples of actual implementation classes.",base class for implementing magic functions.,"classes providing magic functions need to subclass this class, and they
must

use the method decorators @line magic and @cell magic to decorate
individual methods as magic functions, and

use the class decorator @magics class to ensure that the magic
methods are properly registered at the instance level upon instance
initialization.",,"all magic functions should accept a string, which they can parse for their own needs.","shell functions which can be reached as %function name.

this can make some functions easier to type, eg%cd ..
vs. %cd .."
2,MyFrame,"this is myframe. it just shows a few controls on a wxpanel,
and has a simple menu.","this is myframe. it just shows a few controls on a wxpanel,
and has a simple menu.",,,,
2,Obj,namespace to hold arbitrary information.,namespace to hold arbitrary information.,,,,
2,RichPromptDisplayHook,subclass of base display hook using coloured prompt,subclass of base display hook using coloured prompt,,,,
2,Struct,"a dict subclass with attribute style access.

this dict subclass has a a few extra features

attribute style access.
protection of class members like keys, items when using attribute
style access.
the ability to restrict assignment to only existing keys.
intelligent merging.
overloaded operators.",a dict subclass with attribute style access.,,,"this dict subclass has a a few extra features

attribute style access.
protection of class members like keys, items when using attribute
style access.
the ability to restrict assignment to only existing keys.
intelligent merging.
overloaded operators.",
2,TBTools,basic tools used by all traceback printer classes.,basic tools used by all traceback printer classes.,,,,
2,TermColors,"color escape sequences.

this class defines the escape sequences for all the standard ansi?
colors in terminals. also defines a nocolor escape which is just the null
string, suitable for defining dummy color schemes in terminals which get
confused by color escapes.

this class should be used as a mixin for building color schemes.","color escape sequences.

this class defines the escape sequences for all the standard ansi?
colors in terminals. also defines a nocolor escape which is just the null
string, suitable for defining dummy color schemes in terminals which get
confused by color escapes.",this class should be used as a mixin for building color schemes.,,,
2,UserMagics,"placeholder for user defined magics to be added at runtime.

all magics are eventually merged into a single namespace at runtime, but we
use this class to isolate the magics defined dynamically by the user into
their own class.",placeholder for user defined magics to be added at runtime.,,,"all magics are eventually merged into a single namespace at runtime, but we
use this class to isolate the magics defined dynamically by the user into
their own class.","all magics are eventually merged into a single namespace at runtime, but we
use this class to isolate the magics defined dynamically by the user into
their own class."
2,YouTubeVideo,"class for embedding a youtube video in an ipython session, based on its video id.

eg to embed the video from https www.youtube.com watch?v foo , you would
do

vid youtubevideo foo
display vid

to start from 30 seconds

vid youtubevideo abc , start 30
display vid

to calculate seconds from time as hours, minutes, seconds use
class datetime.timedelta

start int timedelta hours 1, minutes 46, seconds 40 .total seconds

other parameters can be provided as documented at
https developers.google.com youtube player parameters#parameters

when converting the notebook using nbconvert, a jpeg representation of the video
will be inserted in the document.","class for embedding a youtube video in an ipython session, based on its video id.","when converting the notebook using nbconvert, a jpeg representation of the video
will be inserted in the document.

eg to embed the video from https www.youtube.com watch?v foo , you would
do

vid youtubevideo foo
display vid

to start from 30 seconds

vid youtubevideo abc , start 30
display vid

to calculate seconds from time as hours, minutes, seconds use
class datetime.timedelta

start int timedelta hours 1, minutes 46, seconds 40 .total seconds","other parameters can be provided as documented at
https developers.google.com youtube player parameters#parameters",,
3,_MockPOP3,"base mock that pretends to be a poplib pop3 connection.

pm pop3mailbox localhost , user bad , conn cls mockpop3
traceback most recent call last

accesserror

pm pop3mailbox localhost , user a , password b ,
conn cls mockpop3
pm.stat
2, 123456

pm.iterkeys
evil , good

evil in pm, bogon in pm
true, false

msg subject for msg in pm
msg 1 , msg 2

pm.get msg size evil , pm.get msg size good
47, 51

pm.get bytes evil
from test@mailpile.is nsubject msg 1 n noh, hi! n

pm.get bytes evil , 5
from

pm invalid key
traceback most recent call last

keyerror ...",base mock that pretends to be a poplib pop3 connection.,"pm pop3mailbox localhost , user bad , conn cls mockpop3
traceback most recent call last

accesserror

pm pop3mailbox localhost , user a , password b ,
conn cls mockpop3
pm.stat
2, 123456

pm.iterkeys
evil , good

evil in pm, bogon in pm
true, false

msg subject for msg in pm
msg 1 , msg 2

pm.get msg size evil , pm.get msg size good
47, 51

pm.get bytes evil
from test@mailpile.is nsubject msg 1 n noh, hi! n

pm.get bytes evil , 5
from

pm invalid key
traceback most recent call last

keyerror ...",,,
3,AutocryptSearch,search for the autocrypt database.,search for the autocrypt database.,,,,
3,AutoTlsConnBroker,"this broker tries to auto upgrade connections to use tls, or at
least do the ssl handshake here so we can record info about it.","this broker tries to auto upgrade connections to use tls, or at
least do the ssl handshake here so we can record info about it.",,,,
3,ConfigDict,"a sanity checking, self documenting dictionary of program settings.

the object must be initialized with a dictionary which describes in
a structured way what variables exist, what their legal values are,
and what their defaults are and what they are for.

each variable definition expects three values
1. a human readable description of what the variable is
2. a data type sanity check
3. a default value

if the sanity check is itself a dictionary of rules, values are expected
to be dictionaries or lists of items that match the rules defined. this
should be used with an empty list or dictionary as a default value.

configuration data can be nested by including a dictionary of further
rules in place of the default value.

if the default value is an empty list, it is assumed to be a list of
values of the type specified.

examples

pot configdict rules potatoes how many potatoes? , int , 0 ,
carrots how many carrots? , int, 99 ,
liquids fluids we like , false,
water liters , int, 0 ,
vodka liters , int, 12
,
tags tags , c c , int, 0 ,
x x , str, , ,
colors colors , red , blue ,
sorted pot.keys , sorted pot.values
colors , liquids , tags , , ,

pot potatoes pot liquids vodka 123
pot potatoes
123
pot liquids vodka
123
pot carrots
99

pot.walk liquids.vodka
123
pot.walk liquids vodka , parent true
, vodka

pot colors .append red
0
pot colors .extend blue , red , red
pot colors
red , blue , red , red

pot tags .append c 123 , x woots
0
pot tags 0 c
123
pot tags .append z invalid
traceback most recent call last

valueerror invalid value for config tags 1 ...

pot evil 123
traceback most recent call last

invalidkeyerror invalid key for config evil
pot liquids evil 123
traceback most recent call last

invalidkeyerror invalid key for config liquids evil
pot potatoes moo
traceback most recent call last

valueerror invalid value for config potatoes moo
pot colors .append green
traceback most recent call last

configvalueerror invalid value for config colors 4 green

pot.rules potatoes
how many potatoes? , type int , 0

isinstance pot liquids , configdict
true","a sanity checking, self documenting dictionary of program settings.","examples

pot configdict rules potatoes how many potatoes? , int , 0 ,
carrots how many carrots? , int, 99 ,
liquids fluids we like , false,
water liters , int, 0 ,
vodka liters , int, 12
,
tags tags , c c , int, 0 ,
x x , str, , ,
colors colors , red , blue ,
sorted pot.keys , sorted pot.values
colors , liquids , tags , , ,

pot potatoes pot liquids vodka 123
pot potatoes
123
pot liquids vodka
123
pot carrots
99

pot.walk liquids.vodka
123
pot.walk liquids vodka , parent true
, vodka

pot colors .append red
0
pot colors .extend blue , red , red
pot colors
red , blue , red , red

pot tags .append c 123 , x woots
0
pot tags 0 c
123
pot tags .append z invalid
traceback most recent call last

valueerror invalid value for config tags 1 ...

pot evil 123
traceback most recent call last

invalidkeyerror invalid key for config evil
pot liquids evil 123
traceback most recent call last

invalidkeyerror invalid key for config liquids evil
pot potatoes moo
traceback most recent call last

valueerror invalid value for config potatoes moo
pot colors .append green
traceback most recent call last

configvalueerror invalid value for config colors 4 green

pot.rules potatoes
how many potatoes? , type int , 0

isinstance pot liquids , configdict
true","each variable definition expects three values
1. a human readable description of what the variable is
2. a data type sanity check
3. a default value","the object must be initialized with a dictionary which describes in
a structured way what variables exist, what their legal values are,
and what their defaults are and what they are for.

each variable definition expects three values
1. a human readable description of what the variable is
2. a data type sanity check
3. a default value

if the sanity check is itself a dictionary of rules, values are expected
to be dictionaries or lists of items that match the rules defined. this
should be used with an empty list or dictionary as a default value.

configuration data can be nested by including a dictionary of further
rules in place of the default value.

if the default value is an empty list, it is assumed to be a list of
values of the type specified.","if the default value is an empty list, it is assumed to be a list of
values of the type specified."
3,ConfigureMailboxes,"add one or more mailboxes.

if not account is specified, the mailbox is only assigned an id for use
in the metadata index.

if an account is specified, the mailbox will be assigned to that account
and configured for automatic indexing.",add one or more mailboxes.,,,,"if not account is specified, the mailbox is only assigned an id for use
in the metadata index.

if an account is specified, the mailbox will be assigned to that account
and configured for automatic indexing."
3,ConnectToGuiOMatic,connect to a waiting gui o matic gui,connect to a waiting gui o matic gui,,,,
3,ContactSet,"set contact lines, ensuring contact exists","set contact lines, ensuring contact exists",,,,
3,EncryptedIntDict,"encrypteddict which only deals in signed 64 bit int values.
this also adds a working keys function.",encrypteddict which only deals in signed 64 bit int values.,,,this also adds a working keys function.,
3,EncryptedUnicodeDict,encrypteddict which only deals in unicode values.,encrypteddict which only deals in unicode values.,,,,
3,Event,"this is a single event in the event log. actual interpretation and
rendering of events should be handled by the respective source class.",this is a single event in the event log.,,,"actual interpretation and
rendering of events should be handled by the respective source class.",
3,Forward,create forwarding drafts of one or more messages,create forwarding drafts of one or more messages,,,,
3,Group_,view groups,view groups,,,,
3,HashCash,try to collide a hash using the smtorp algorithm,try to collide a hash using the smtorp algorithm,,,,
3,ListTags,list tags,list tags,,,,
3,MailpileJinjaLoader,"a jinja2 template loader which uses the mailpile configuration
and plugin system to find template files.","a jinja2 template loader which uses the mailpile configuration
and plugin system to find template files.",,,,
3,MailpileMailbox,a maildir class for windows using ! instead of in filenames,a maildir class for windows using ! instead of in filenames,,,,
3,MailpileVFS,"this is a router object that implements the vfs interface but,
delegating calls to individual implementations.","this is a router object that implements the vfs interface but,
delegating calls to individual implementations.",,,,
3,MoveFilter,move an auto tagging rule,move an auto tagging rule,,,,
3,OldPostingList,a posting list is a map of search terms to message ids.,a posting list is a map of search terms to message ids.,,,,
3,Rescan,add new messages to index,add new messages to index,,,,
3,StorageBackedLongs,"this combines storagebackeddata with pack unpacklonglist to pack
and save sets of ints.

storage sbl x01 x00 x00 x00 x00 x00 x00 x00
sbl storagebackedlongs storage, sbl
1 in sbl
true

sbl.append 2
sbl.save
unpacklonglist storage sbl 1, 2
true","this combines storagebackeddata with pack unpacklonglist to pack
and save sets of ints.","storage sbl x01 x00 x00 x00 x00 x00 x00 x00
sbl storagebackedlongs storage, sbl
1 in sbl
true

sbl.append 2
sbl.save
unpacklonglist storage sbl 1, 2
true",,,
3,Util,utility functions for builds,utility functions for builds,,,,
3,Vcard,display a single vcard,display a single vcard,,,,
3,VCardSet,"add a lines to a vcard, ensuring vcard exists","add a lines to a vcard, ensuring vcard exists",,,,
3,VCardStore,"this is a disk backed in memory collection of vcards.

vcs vcardstore cfg, tmp

# vcards are added to the collection using add vcard. this will
# create a file for the card on disk, using a random name.
vcs.add vcards mailpilevcard vcardline fn dude ,
vcardline email d@evil.com ,
mailpilevcard vcardline fn guy

vcards can be looked up directly by e mail.
vcs.get vcard d@evil.com .fn
u dude
vcs.get vcard nosuch@email.address is none
true

or they can be found using searches...
vcs.find vcards guy 0 .fn
u guy

cards can be removed using del vcards
vcs.del vcards vcs.get vcard d@evil.com
vcs.get vcard d@evil.com is none
true
vcs.del vcards vcs.find vcards guy
vcs.find vcards guy",this is a disk backed in memory collection of vcards.,"# vcards are added to the collection using add vcard. this will
# create a file for the card on disk, using a random name.
vcs.add vcards mailpilevcard vcardline fn dude ,
vcardline email d@evil.com ,
mailpilevcard vcardline fn guy

vcards can be looked up directly by e mail.
vcs.get vcard d@evil.com .fn
u dude
vcs.get vcard nosuch@email.address is none
true

or they can be found using searches...
vcs.find vcards guy 0 .fn
u guy

cards can be removed using del vcards
vcs.del vcards vcs.get vcard d@evil.com
vcs.get vcard d@evil.com is none
true
vcs.del vcards vcs.find vcards guy
vcs.find vcards guy",,,
4,_MergeOperation,"perform a database sql merge operation between two dataframe or series
objects using either columns as keys or their row indexes",,perform a database sql merge operation between two dataframe or series objects using either columns as keys or their row indexes,,,
4,AbstractEngine,object serving as a base class for all engines.,object serving as a base class for all engines.,,,,
4,AbstractHolidayCalendar,abstract interface to create holidays following certain rules.,abstract interface to create holidays following certain rules.,,,,
4,AccessorCallableDocumenter,"this documenter lets us removes . call from the method signature for
callable accessors like series.plot","this documenter lets us removes . call from the method signature for
callable accessors like series.plot",,,,
4,AccessorDocumenter,specialized documenter subclass for accessors.,specialized documenter subclass for accessors.,,,,
4,Base,"common tests for all variations of intervalindex construction. input data
to be supplied in breaks format, then converted by the subclass method
get kwargs from breaks to the expected format.",common tests for all variations of intervalindex construction.,,,"input data to be supplied in breaks format, then converted by the subclass method get kwargs from breaks to the expected format.","input data
to be supplied in breaks format, then converted by the subclass method
get kwargs from breaks to the expected format."
4,BaseInterfaceTests,"tests that the basic interface is satisfied.

interface","tests that the basic interface is satisfied.

interface",,,,
4,BooleanArray,"array of boolean true false data with missing values.

this is a pandas extension array for boolean data, under the hood
represented by 2 numpy arrays a boolean array with the data and
a boolean array with the mask true indicating missing .

booleanarray implements kleene logic sometimes called three value
logic for logical operations. see ref boolean.kleene for more.

to construct an booleanarray from generic array like input, use
func pandas.array specifying dtype boolean see examples
below .

versionadded 10.0

warning

booleanarray is considered experimental. the implementation and
parts of the api may change without warning.

parameters

values numpy.ndarray
a 1 d boolean dtype array with the data.
mask numpy.ndarray
a 1 d boolean dtype array indicating missing values true
indicates missing .
copy bool, default false
whether to copy the values and mask arrays.

attributes

none

methods

none

returns

booleanarray

examples

create an booleanarray with func pandas.array

pd.array true, false, none , dtype boolean
booleanarray
true, false, na
length 3, dtype boolean",array of boolean true false data with missing values.,"examples

create an booleanarray with func pandas.array

pd.array true, false, none , dtype boolean
booleanarray
true, false, na
length 3, dtype boolean","parameters

values numpy.ndarray
a 1 d boolean dtype array with the data.
mask numpy.ndarray
a 1 d boolean dtype array indicating missing values true
indicates missing .
copy bool, default false
whether to copy the values and mask arrays.","this is a pandas extension array for boolean data, under the hood
represented by 2 numpy arrays a boolean array with the data and
a boolean array with the mask true indicating missing .

booleanarray implements kleene logic sometimes called three value
logic for logical operations. see ref boolean.kleene for more.

to construct an booleanarray from generic array like input, use
func pandas.array specifying dtype boolean see examples
below .

attributes

none

methods

none

returns

booleanarray",
4,BusinessHour,dateoffset subclass representing possibly n business hours.,dateoffset subclass representing possibly n business hours.,,,,
4,BusinessMixin,mixin to business types to provide related functions.,mixin to business types to provide related functions.,,,,
4,BYearBegin,dateoffset increments between business year begin dates.,dateoffset increments between business year begin dates.,,,,
4,CategoricalDtype,"type for categorical data with the categories and orderedness.

versionchanged 021.0

parameters

categories sequence, optional
must be unique, and must not contain any nulls.
ordered bool or none, default false
whether or not this categorical is treated as a ordered categorical.
none can be used to maintain the ordered value of existing categoricals when
used in operations that combine categoricals, eg astype, and will resolve to
false if there is no existing ordered to maintain.

attributes

categories
ordered

methods

none

see also

categorical

notes

this class is useful for specifying the type of a categorical
independent of the values. see ref categorical.categoricaldtype
for more.

examples

t pd.categoricaldtype categories b , a , ordered true
pd.series a , b , a , c , dtype t
0 a
1 b
2 a
3 nan
dtype category
categories 2, object b a",type for categorical data with the categories and orderedness.,"examples

t pd.categoricaldtype categories b , a , ordered true
pd.series a , b , a , c , dtype t
0 a
1 b
2 a
3 nan
dtype category
categories 2, object b a","parameters

categories sequence, optional
must be unique, and must not contain any nulls.
ordered bool or none, default false
whether or not this categorical is treated as a ordered categorical.
none can be used to maintain the ordered value of existing categoricals when
used in operations that combine categoricals, eg astype, and will resolve to
false if there is no existing ordered to maintain.","attributes

categories
ordered
methods

none","notes

this class is useful for specifying the type of a categorical
independent of the values. see ref categorical.categoricaldtype
for more."
4,CategoricalIndex,"index based on an underlying class categorical .

categoricalindex, like categorical, can only take on a limited,
and usually fixed, number of possible values categories . also,
like categorical, it might have an order, but numerical operations
additions, divisions, ... are not possible.

parameters

data array like 1 dimensional
the values of the categorical. if categories are given, values not in
categories will be replaced with nan.
categories index like, optional
the categories for the categorical. items need to be unique.
if the categories are not given here and also not in dtype , they
will be inferred from the data .
ordered bool, optional
whether or not this categorical is treated as an ordered
categorical. if not given here or in dtype , the resulting
categorical will be unordered.
dtype categoricaldtype or category , optional
if class categoricaldtype , cannot be used together with
categories or ordered .

versionadded 021.0
copy bool, default false
make a copy of input ndarray.
name object, optional
name to be stored in the index.

attributes

codes
categories
ordered

methods

rename categories
reorder categories
add categories
remove categories
remove unused categories
set categories
as ordered
as unordered
map

raises

valueerror
if the categories do not validate.
typeerror
if an explicit ordered true is given but no categories and the
values are not sortable.

see also

index the base pandas index type.
categorical a categorical array.
categoricaldtype type for categorical data.

notes

see the user guide
http pandas.pydata.org pandas docs stable user guide advanced.html#categoricalindex
for more.

examples

pd.categoricalindex a , b , c , a , b , c
categoricalindex a , b , c , a , b , c , categories a , b , c , ordered false, dtype category # noqa

categoricalindex can also be instantiated from a categorical

c pd.categorical a , b , c , a , b , c
pd.categoricalindex c
categoricalindex a , b , c , a , b , c , categories a , b , c , ordered false, dtype category # noqa

ordered categoricalindex can have a min and max value.

ci pd.categoricalindex a , b , c , a , b , c , ordered true,
categories c , b , a
ci
categoricalindex a , b , c , a , b , c , categories c , b , a , ordered true, dtype category # noqa
ci.min
c",index based on an underlying class categorical .,"examples

pd.categoricalindex a , b , c , a , b , c
categoricalindex a , b , c , a , b , c , categories a , b , c , ordered false, dtype category # noqa

categoricalindex can also be instantiated from a categorical

c pd.categorical a , b , c , a , b , c
pd.categoricalindex c
categoricalindex a , b , c , a , b , c , categories a , b , c , ordered false, dtype category # noqa

ordered categoricalindex can have a min and max value.

ci pd.categoricalindex a , b , c , a , b , c , ordered true,
categories c , b , a
ci
categoricalindex a , b , c , a , b , c , categories c , b , a , ordered true, dtype category # noqa
ci.min
c","parameters

data array like 1 dimensional
the values of the categorical. if categories are given, values not in
categories will be replaced with nan.
categories index like, optional
the categories for the categorical. items need to be unique.
if the categories are not given here and also not in dtype , they
will be inferred from the data .
ordered bool, optional
whether or not this categorical is treated as an ordered
categorical. if not given here or in dtype , the resulting
categorical will be unordered.
dtype categoricaldtype or category , optional
if class categoricaldtype , cannot be used together with
categories or ordered .

versionadded 021.0
copy bool, default false
make a copy of input ndarray.
name object, optional
name to be stored in the index.","categoricalindex, like categorical, can only take on a limited,
and usually fixed, number of possible values categories . also,
like categorical, it might have an order, but numerical operations
additions, divisions, ... are not possible.

methods

rename categories
reorder categories
add categories
remove categories
remove unused categories
set categories
as ordered
as unordered
map
attributes

codes
categories
ordered","notes

see the user guide
http pandas.pydata.org pandas docs stable user guide advanced.html#categoricalindex
for more."
4,CheckingBuildExt,subclass build ext to get clearer report if cython is necessary.,,,,,
4,CythonCommand,"custom distutils command subclassed from cython.distutils.build ext
to compile pyx c, and stop there. all this does is override the
c compile method build extension with a no op.","custom distutils command subclassed from cython.distutils.build ext
to compile pyx c, and stop there.",,,,
4,DataIndexableCol,represent a data column that can be indexed,represent a data column that can be indexed,,,,
4,ExcelFile,"class for parsing tabular excel sheets into dataframe objects.
uses xlrd. see read excel for more documentation

parameters

io str, path object pathlib.path or py. path.local.localpath ,
a file like object, xlrd workbook or openpypl workbook.
if a string or path object, expected to be a path to xls, xlsx or odf file.
engine str, default none
if io is not a buffer or path, this must be set to identify io.
acceptable values are none, xlrd , openpyxl or odf .
note that odf reads tables out of opendocument formatted files.",class for parsing tabular excel sheets into dataframe objects.,,"parameters

io str, path object pathlib.path or py. path.local.localpath ,
a file like object, xlrd workbook or openpypl workbook.
if a string or path object, expected to be a path to xls, xlsx or odf file.
engine str, default none
if io is not a buffer or path, this must be set to identify io.
acceptable values are none, xlrd , openpyxl or odf .
note that odf reads tables out of opendocument formatted files.",,uses xlrd. see read excel for more documentation
4,Holiday,"class that defines a holiday with start end dates and rules
for observance.","class that defines a holiday with start end dates and rules
for observance.",,,,
4,IntegerArray,"array of integer optional missing values.

versionadded 024.0

warning

integerarray is currently experimental, and its api or internal
implementation may change without warning.

we represent an integerarray with 2 numpy arrays

data contains a numpy integer array of the appropriate dtype
mask a boolean array holding a mask on the data, true is missing

to construct an integerarray from generic array like input, use
func pandas.array with one of the integer dtypes see examples .

see ref integer na for more.

parameters

values numpy.ndarray
a 1 d integer dtype array.
mask numpy.ndarray
a 1 d boolean dtype array indicating missing values.
copy bool, default false
whether to copy the values and mask .

attributes

none

methods

none

returns

integerarray

examples

create an integerarray with func pandas.array .

int array pd.array 1, none, 3 , dtype pd.int32dtype
int array
integerarray
1, nan, 3
length 3, dtype int32

string aliases for the dtypes are also available. they are capitalized.

pd.array 1, none, 3 , dtype int32
integerarray
1, nan, 3
length 3, dtype int32

pd.array 1, none, 3 , dtype uint16
integerarray
1, nan, 3
length 3, dtype uint16",array of integer optional missing values.,"to construct an integerarray from generic array like input, use
func pandas.array with one of the integer dtypes see examples .
examples

create an integerarray with func pandas.array .

int array pd.array 1, none, 3 , dtype pd.int32dtype
int array
integerarray
1, nan, 3
length 3, dtype int32

string aliases for the dtypes are also available. they are capitalized.

pd.array 1, none, 3 , dtype int32
integerarray
1, nan, 3
length 3, dtype int32

pd.array 1, none, 3 , dtype uint16
integerarray
1, nan, 3
length 3, dtype uint16","parameters

values numpy.ndarray
a 1 d integer dtype array.
mask numpy.ndarray
a 1 d boolean dtype array indicating missing values.
copy bool, default false
whether to copy the values and mask .","attributes

none

methods

none

returns

integerarray
we represent an integerarray with 2 numpy arrays

data contains a numpy integer array of the appropriate dtype
mask a boolean array holding a mask on the data, true is missing

to construct an integerarray from generic array like input, use
func pandas.array with one of the integer dtypes see examples .","we represent an integerarray with 2 numpy arrays

data contains a numpy integer array of the appropriate dtype
mask a boolean array holding a mask on the data, true is missing

to construct an integerarray from generic array like input, use
func pandas.array with one of the integer dtypes see examples ."
4,IntervalDtype,"an extensiondtype for interval data.

this is not an actual numpy dtype , but a duck type.

parameters

subtype str, np.dtype
the dtype of the interval bounds.

attributes

subtype

methods

none

examples

pd.intervaldtype subtype int64
interval int64",an extensiondtype for interval data.,"examples

pd.intervaldtype subtype int64
interval int64","parameters

subtype str, np.dtype
the dtype of the interval bounds.","attributes

subtype
methods

none","this is not an actual numpy dtype , but a duck type."
4,NonConsolidatableMixIn,hold methods for the nonconsolidatable blocks,hold methods for the nonconsolidatable blocks,,,,
4,PlotAccessor,"make plots of series or dataframe.

uses the backend specified by the
option plotting.backend . by default, matplotlib is used.

parameters

data series or dataframe
the object for which the method is called.
x label or position, default none
only used if data is a dataframe.
y label, position or list of label, positions, default none
allows plotting of one column versus another. only used if data is a
dataframe.
kind str
the kind of plot to produce

line line plot default
bar vertical bar plot
barh horizontal bar plot
hist histogram
box boxplot
kde kernel density estimation plot
density same as kde
area area plot
pie pie plot
scatter scatter plot
hexbin hexbin plot.

figsize a tuple width, height in inches
use index bool, default true
use index as ticks for x axis.
title str or list
title to use for the plot. if a string is passed, print the string
at the top of the figure. if a list is passed and subplots is
true, print each item in the list above the corresponding subplot.
grid bool, default none matlab style default
axis grid lines.
legend bool or reverse
place legend on axis subplots.
style list or dict
the matplotlib line style per column.
logx bool or sym , default false
use log scaling or symlog scaling on x axis.
versionchanged 025.0

logy bool or sym default false
use log scaling or symlog scaling on y axis.
versionchanged 025.0

loglog bool or sym , default false
use log scaling or symlog scaling on both x and y axes.
versionchanged 025.0

xticks sequence
values to use for the xticks.
yticks sequence
values to use for the yticks.
xlim 2 tuple list
ylim 2 tuple list
rot int, default none
rotation for ticks xticks for vertical, yticks for horizontal
plots .
fontsize int, default none
font size for xticks and yticks.
colormap str or matplotlib colormap object, default none
colormap to select colors from. if string, load colormap with that
name from matplotlib.
colorbar bool, optional
if true, plot colorbar only relevant for scatter and hexbin
plots .
position float
specify relative alignments for bar plot layout.
from 0 left bottom end to 1 right top end . default is 05
center .
table bool, series or dataframe, default false
if true, draw a table using the data in the dataframe and the data
will be transposed to meet matplotlib s default layout.
if a series or dataframe is passed, use passed data to draw a
table.
yerr dataframe, series, array like, dict and str
see ref plotting with error bars visualization.errorbars for
detail.
xerr dataframe, series, array like, dict and str
equivalent to yerr.
mark right bool, default true
when using a secondary y axis, automatically mark the column
labels with right in the legend.
include bool bool, default is false
if true, boolean values can be plotted.
backend str, default none
backend to use instead of the backend specified in the option
plotting.backend . for instance, matplotlib . alternatively, to
specify the plotting.backend for the whole session, set
pd.options.plotting.backend .

versionadded 10.0

kwargs
options to pass to matplotlib plotting method.

returns

class matplotlib.axes.axes or numpy.ndarray of them
if the backend is not the default matplotlib one, the return value
will be the object returned by the backend.

notes

see matplotlib documentation online for more on this subject
if kind bar or barh , you can specify relative alignments
for bar plot layout by position keyword.
from 0 left bottom end to 1 right top end . default is 05
center",make plots of series or dataframe.,"uses the backend specified by the
option plotting.backend . by default, matplotlib is used.","parameters

data series or dataframe
the object for which the method is called.
x label or position, default none
only used if data is a dataframe.
y label, position or list of label, positions, default none
allows plotting of one column versus another. only used if data is a
dataframe.
kind str
the kind of plot to produce

line line plot default
bar vertical bar plot
barh horizontal bar plot
hist histogram
box boxplot
kde kernel density estimation plot
density same as kde
area area plot
pie pie plot
scatter scatter plot
hexbin hexbin plot.

figsize a tuple width, height in inches
use index bool, default true
use index as ticks for x axis.
title str or list
title to use for the plot. if a string is passed, print the string
at the top of the figure. if a list is passed and subplots is
true, print each item in the list above the corresponding subplot.
grid bool, default none matlab style default
axis grid lines.
legend bool or reverse
place legend on axis subplots.
style list or dict
the matplotlib line style per column.
logx bool or sym , default false
use log scaling or symlog scaling on x axis.
versionchanged 025.0

logy bool or sym default false
use log scaling or symlog scaling on y axis.
versionchanged 025.0

loglog bool or sym , default false
use log scaling or symlog scaling on both x and y axes.
versionchanged 025.0

xticks sequence
values to use for the xticks.
yticks sequence
values to use for the yticks.
xlim 2 tuple list
ylim 2 tuple list
rot int, default none
rotation for ticks xticks for vertical, yticks for horizontal
plots .
fontsize int, default none
font size for xticks and yticks.
colormap str or matplotlib colormap object, default none
colormap to select colors from. if string, load colormap with that
name from matplotlib.
colorbar bool, optional
if true, plot colorbar only relevant for scatter and hexbin
plots .
position float
specify relative alignments for bar plot layout.
from 0 left bottom end to 1 right top end . default is 05
center .
table bool, series or dataframe, default false
if true, draw a table using the data in the dataframe and the data
will be transposed to meet matplotlib s default layout.
if a series or dataframe is passed, use passed data to draw a
table.
yerr dataframe, series, array like, dict and str
see ref plotting with error bars visualization.errorbars for
detail.
xerr dataframe, series, array like, dict and str
equivalent to yerr.
mark right bool, default true
when using a secondary y axis, automatically mark the column
labels with right in the legend.
include bool bool, default is false
if true, boolean values can be plotted.
backend str, default none
backend to use instead of the backend specified in the option
plotting.backend . for instance, matplotlib . alternatively, to
specify the plotting.backend for the whole session, set
pd.options.plotting.backend .

versionadded 10.0

kwargs
options to pass to matplotlib plotting method.

returns

class matplotlib.axes.axes or numpy.ndarray of them
if the backend is not the default matplotlib one, the return value
will be the object returned by the backend.","if kind bar or barh , you can specify relative alignments
for bar plot layout by position keyword.
from 0 left bottom end to 1 right top end . default is 05
center","uses the backend specified by the
option plotting.backend . by default, matplotlib is used.

notes

see matplotlib documentation online for more on this subject
if kind bar or barh , you can specify relative alignments
for bar plot layout by position keyword.
from 0 left bottom end to 1 right top end . default is 05
center"
4,SelectNSeries,"implement n largest smallest for series

parameters

obj series
n int
keep first , last , default first

returns

nordered series",implement n largest smallest for series,,"parameters

obj series
n int
keep first , last , default first

returns

nordered series",,
4,SetopCheck,"this is called to decorate the set operations of intervalindex
to perform the type check in advance.","this is called to decorate the set operations of intervalindex
to perform the type check in advance.",,,,"this is called to decorate the set operations of intervalindex
to perform the type check in advance."
4,SQLiteTable,"patch the sqltable for fallback support.
instead of a table variable just use the create table statement.",patch the sqltable for fallback support.,,,,instead of a table variable just use the create table statement.
4,SQLTable,"for mapping pandas tables to sql tables.
uses fact that table is reflected by sqlalchemy to
do better type conversions.
also holds various flags needed to avoid having to
pass them between functions all the time.
todo support for multiindex",for mapping pandas tables to sql tables.,,,"uses fact that table is reflected by sqlalchemy to
do better type conversions.
also holds various flags needed to avoid having to
pass them between functions all the time.",
4,StringArray,"extension array for string data.

versionadded 10.0

warning

stringarray is considered experimental. the implementation and
parts of the api may change without warning.

in particular, the na value used may change to no longer be
numpy.nan .

parameters

values array like
the array of data.

warning

currently, this expects an object dtype ndarray
where the elements are python strings. this may
change without warning in the future.
copy bool, default false
whether to copy the array of data.

attributes

none

methods

none

see also

series.str
the string methods are available on series backed by
a stringarray.

notes

stringarray returns a booleanarray for comparison methods.

examples

pd.array this is , some text , none, data. , dtype string
stringarray
this is , some text , na, data.
length 4, dtype string

unlike object dtype arrays, stringarray doesn t allow non string
values.

pd.array 1 , 1 , dtype string
traceback most recent call last

valueerror stringarray requires an object dtype ndarray of strings.

for comparison methods, this returns a class pandas.booleanarray

pd.array a , none, c , dtype string a
booleanarray
true, na, false
length 3, dtype boolean",extension array for string data.,"examples

pd.array this is , some text , none, data. , dtype string
stringarray
this is , some text , na, data.
length 4, dtype string

unlike object dtype arrays, stringarray doesn t allow non string
values.

pd.array 1 , 1 , dtype string
traceback most recent call last

valueerror stringarray requires an object dtype ndarray of strings.

for comparison methods, this returns a class pandas.booleanarray

pd.array a , none, c , dtype string a
booleanarray
true, na, false","parameters

values array like
the array of data.

warning

currently, this expects an object dtype ndarray
where the elements are python strings. this may
change without warning in the future.
copy bool, default false
whether to copy the array of data.","attributes

none
for comparison methods, this returns a class pandas.booleanarray
methods

none","notes

stringarray returns a booleanarray for comparison methods."
4,StringMethods,"vectorized string functions for series and index. nas stay na unless
handled otherwise by a particular method. patterned after python s string
methods, with some inspiration from r s stringr package.

examples

s.str.split
s.str.replace ,",vectorized string functions for series and index.,"examples

s.str.split
s.str.replace ,",,,"nas stay na unless
handled otherwise by a particular method. patterned after python s string
methods, with some inspiration from r s stringr package."
4,TermValue,hold a term value the we use to construct a condition filter,hold a term value the we use to construct a condition filter,,,,
4,TestDatetimelikeSubtype,tests specific to intervalindex with datetime like subtype,tests specific to intervalindex with datetime like subtype,,,,
4,TestFromArrays,tests specific to intervalindex.from arrays,tests specific to intervalindex.from arrays,,,,
4,TestFromTuples,tests specific to intervalindex.from tuples,tests specific to intervalindex.from tuples,,,,
4,TestPeriodIndexSeriesComparisonConsistency,"test periodindex and period series ops consistency
todo needs parametrization de duplication",test periodindex and period series ops consistency,,,,
4,TestSorted,everything you wanted to test about sorting,everything you wanted to test about sorting,,,,
4,UnsortedIndexError,"error raised when attempting to get a slice of a multiindex,
and the index has not been lexsorted. subclass of keyerror .","error raised when attempting to get a slice of a multiindex,
and the index has not been lexsorted.",,,subclass of keyerror .,
5,_BZ2Proxy,"small proxy class that enables external file object
support for r bz2 and w bz2 modes. this is actually
a workaround for a limitation in bz2 module s bz2file
class which unlike gzip.gzipfile has no support for
a file object argument.","small proxy class that enables external file object
support for r bz2 and w bz2 modes.",,,,"this is actually
a workaround for a limitation in bz2 module s bz2file
class which unlike gzip.gzipfile has no support for
a file object argument."
5,_FileInFile,"a thin wrapper around an existing file object that
provides a part of its data as an individual file
object.","a thin wrapper around an existing file object that
provides a part of its data as an individual file
object.",,,,
5,_MovedItems,lazy loading of moved objects,lazy loading of moved objects,,,,
5,_PathParents,"this object provides sequence like access to the logical ancestors
of a path. don t try to construct it yourself.","this object provides sequence like access to the logical ancestors
of a path.",,,,
5,And,"requires all given class parseexpression s to be found in the given order.
expressions may be separated by whitespace.
may be constructed using the operator.
may also be constructed using the operator, which will
suppress backtracking.

example

integer word nums
name expr oneormore word alphas

expr and integer id ,name expr name ,integer age
# more easily written as
expr integer id name expr name integer age",,"example

integer word nums
name expr oneormore word alphas

expr and integer id ,name expr name ,integer age
# more easily written as
expr integer id name expr name integer age",,"expressions may be separated by whitespace.
may be constructed using the operator.
may also be constructed using the operator, which will
suppress backtracking.","requires all given class parseexpression s to be found in the given order.
expressions may be separated by whitespace.
may be constructed using the operator.
may also be constructed using the operator, which will
suppress backtracking."
5,Argument,"arguments are positional parameters to a command. they generally
provide fewer features than options but can have infinite nargs
and are required by default.

all parameters are passed onwards to the parameter constructor.",arguments are positional parameters to a command.,"they generally
provide fewer features than options but can have infinite nargs
and are required by default.",,all parameters are passed onwards to the parameter constructor,
5,BaseCommand_,a cli command.,a cli command.,,,,
5,BrokenStdoutLoggingError,raised if brokenpipeerror occurs for the stdout stream while logging.,raised if brokenpipeerror occurs for the stdout stream while logging.,,,,
5,Bucket,"buckets are used to store the bytecode for one template. it s created
and initialized by the bytecode cache and passed to the loading functions.

the buckets get an internal checksum from the cache assigned and use this
to automatically reject outdated cache material. individual bytecode
cache subclasses don t have to care about cache invalidation.","buckets are used to store the bytecode for one template. it s created
and initialized by the bytecode cache and passed to the loading functions.",,,"the buckets get an internal checksum from the cache assigned and use this
to automatically reject outdated cache material.",
5,CallBlock,"like a macro without a name but a call instead. call is called with
the unnamed macro as caller argument this node holds.",,,"call is called with
the unnamed macro as caller argument this node holds.",,like a macro without a name but a call instead.
5,CaseInsensitiveDict,"a case insensitive dict like object.

implements all methods and operations of
mutablemapping as well as dict s copy . also
provides lower items .

all keys are expected to be strings. the structure remembers the
case of the last key to be set, and iter instance ,
keys , items , iterkeys , and iteritems
will contain case sensitive keys. however, querying and contains
testing is case insensitive

cid caseinsensitivedict
cid accept application json
cid accept application json # true
list cid accept # true

for example, headers content encoding will return the
value of a content encoding response header, regardless
of how the header name was originally stored.

if the constructor, .update , or equality comparison
operations are given keys that have equal .lower s, the
behavior is undefined.","a case insensitive dict like object.

implements all methods and operations of
mutablemapping as well as dict s copy . also
provides lower items .","however, querying and contains
testing is case insensitive

cid caseinsensitivedict
cid accept application json
cid accept application json # true
list cid accept # true

for example, headers content encoding will return the
value of a content encoding response header, regardless
of how the header name was originally stored.

if the constructor, .update , or equality comparison
operations are given keys that have equal .lower s, the
behavior is undefined.",,"all keys are expected to be strings. the structure remembers the
case of the last key to be set, and iter instance ,
keys , items , iterkeys , and iteritems
will contain case sensitive keys.","all keys are expected to be strings.

the structure remembers the
case of the last key to be set, and iter instance ,
keys , items , iterkeys , and iteritems
will contain case sensitive keys."
5,ColoredString,enhanced string for len operations on colored output.,enhanced string for len operations on colored output.,,,,
5,CommandError,raised when there is an error in command line arguments,raised when there is an error in command line arguments,,,,
5,ConnectionError,a connection error occurred.,a connection error occurred.,,,,
5,CONSOLE_SCREEN_BUFFER_INFO,struct in wincon.h.,struct in wincon.h.,,,,
5,Context_,"the template context holds the variables of a template. it stores the
values passed to the template and also the names the template exports.
creating instances is neither supported nor useful as it s created
automatically at various stages of the template evaluation and should not
be created by hand.

the context is immutable. modifications on attr parent must not
happen and modifications on attr vars are allowed from generated
template code only. template filters and global functions marked as
func contextfunction s get the active context passed as first argument
and are allowed to access the context read only.

the template context supports read only dict operations get ,
keys , values , items , iterkeys , itervalues , iteritems ,
getitem , contains . additionally there is a meth resolve
method that doesn t fail with a keyerror but returns an
class undefined object for missing variables.",the template context holds the variables of a template.,"it stores the values passed to the template and also the names the template exports.

modifications on attr parent must not
happen and modifications on attr vars are allowed from generated
template code only. template filters and global functions marked as
func contextfunction s get the active context passed as first argument
and are allowed to access the context read only.","modifications on attr parent must not
happen and modifications on attr vars are allowed from generated
template code only. template filters and global functions marked as
func contextfunction s get the active context passed as first argument
and are allowed to access the context read only.

the template context supports read only dict operations get ,
keys , values , items , iterkeys , itervalues , iteritems ,
getitem , contains .

additionally there is a meth resolve
method that doesn t fail with a keyerror but returns an
class undefined object for missing variables.",,"creating instances is neither supported nor useful as it s created
automatically at various stages of the template evaluation and should not
be created by hand.

the context is immutable."
5,ConvertingTuple,a converting tuple wrapper.,a converting tuple wrapper.,,,,
5,CookieConflictError,"there are two cookies that meet the criteria specified in the cookie jar.
use .get and .set and include domain and path args in order to be more specific.",there are two cookies that meet the criteria specified in the cookie jar.,,,,use .get and .set and include domain and path args in order to be more specific.
5,DataViewSequence,"a sequence of data views.

each entry is an instance of item class .",a sequence of data views.,,each entry is an instance of item class .,,
5,Date,a date literal.,a date literal.,,,,
5,DependencyWarning,"warned when an attempt is made to import a module with missing optional
dependencies.",warned when an attempt is made to import a module with missing optional dependencies.,,,,
5,DirectedGraph,a graph structure with directed edges.,a graph structure with directed edges.,,,,
5,Distribution,"a base class for distributions, whether installed or from indexes.
either way, it must have some metadata, so that s all that s needed
for construction.","a base class for distributions, whether installed or from indexes.","either way, it must have some metadata, so that s all that s needed
for construction.",,,
5,DocumentErrorTree,"implements a dict like class to query errors by indexes following the
structure of a validated document.",implements a dict like class to query errors,,,by indexes following the structure of a validated document.,
5,Environment,"the core component of jinja is the environment . it contains
important shared variables like configuration, filters, tests,
globals and others. instances of this class may be modified if
they are not shared and if no template was loaded so far.
modifications on environments after the first template was loaded
will lead to surprising effects and undefined behavior.

here are the possible initialization parameters

block start string
the string marking the beginning of a block. defaults to % .

block end string
the string marking the end of a block. defaults to % .

variable start string
the string marking the beginning of a print statement.
defaults to .

variable end string
the string marking the end of a print statement. defaults to


comment start string
the string marking the beginning of a comment. defaults to # .

comment end string
the string marking the end of a comment. defaults to # .

line statement prefix
if given and a string, this will be used as prefix for line based
statements. see also ref line statements .

line comment prefix
if given and a string, this will be used as prefix for line based
comments. see also ref line statements .

versionadded 22

trim blocks
if this is set to true the first newline after a block is
removed block, not variable tag! . defaults to false .

lstrip blocks
if this is set to true leading spaces and tabs are stripped
from the start of a line to a block. defaults to false .

newline sequence
the sequence that starts a newline. must be one of r ,
n or r n . the default is n which is a
useful default for linux and os x systems as well as web
applications.

keep trailing newline
preserve the trailing newline when rendering templates.
the default is false , which causes a single newline,
if present, to be stripped from the end of the template.

versionadded 27

extensions
list of jinja extensions to use. this can either be import paths
as strings or extension classes. for more information have a
look at ref the extensions documentation jinja extensions .

optimized
should the optimizer be enabled? default is true .

undefined
class undefined or a subclass of it that is used to represent
undefined values in the template.

finalize
a callable that can be used to process the result of a variable
expression before it is output. for example one can convert
none implicitly into an empty string here.

autoescape
if set to true the xml html autoescaping feature is enabled by
default. for more details about autoescaping see
class jinja2.utils.markup . as of jinja 24 this can also
be a callable that is passed the template name and has to
return true or false depending on autoescape should be
enabled by default.

versionchanged 24
autoescape can now be a function

loader
the template loader for this environment.

cache size
the size of the cache. per default this is 400 which means
that if more than 400 templates are loaded the loader will clean
out the least recently used template. if the cache size is set to
0 templates are recompiled all the time, if the cache size is
1 the cache will not be cleaned.

versionchanged 28
the cache size was increased to 400 from a low 50.

auto reload
some loaders load templates from locations where the template
sources may change ie file system or database . if
auto reload is set to true default every time a template is
requested the loader checks if the source changed and if yes, it
will reload the template. for higher performance it s possible to
disable that.

bytecode cache
if set to a bytecode cache object, this object will provide a
cache for the internal jinja bytecode so that templates don t
have to be parsed if they were not changed.

see ref bytecode cache for more information.

enable async
if set to true this enables async template execution which allows
you to take advantage of newer python features. this requires
python 36 or later.","the core component of jinja is the environment it contains
important shared variables like configuration, filters, tests,
globals and others. instances of this class may be modified if
they are not shared and if no template was loaded so far.
modifications on environments after the first template was loaded
will lead to surprising effects and undefined behavior.",,"here are the possible initialization parameters

block start string
the string marking the beginning of a block. defaults to % .

block end string
the string marking the end of a block. defaults to % .

variable start string
the string marking the beginning of a print statement.
defaults to .

variable end string
the string marking the end of a print statement. defaults to


comment start string
the string marking the beginning of a comment. defaults to # .

comment end string
the string marking the end of a comment. defaults to # .

line statement prefix
if given and a string, this will be used as prefix for line based
statements. see also ref line statements .

line comment prefix
if given and a string, this will be used as prefix for line based
comments. see also ref line statements .

versionadded 22

trim blocks
if this is set to true the first newline after a block is
removed block, not variable tag! . defaults to false .

lstrip blocks
if this is set to true leading spaces and tabs are stripped
from the start of a line to a block. defaults to false .

newline sequence
the sequence that starts a newline. must be one of r ,
n or r n . the default is n which is a
useful default for linux and os x systems as well as web
applications.

keep trailing newline
preserve the trailing newline when rendering templates.
the default is false , which causes a single newline,
if present, to be stripped from the end of the template.

versionadded 27

extensions
list of jinja extensions to use. this can either be import paths
as strings or extension classes. for more information have a
look at ref the extensions documentation jinja extensions .

optimized
should the optimizer be enabled? default is true .

undefined
class undefined or a subclass of it that is used to represent
undefined values in the template.

finalize
a callable that can be used to process the result of a variable
expression before it is output. for example one can convert
none implicitly into an empty string here.

autoescape
if set to true the xml html autoescaping feature is enabled by
default. for more details about autoescaping see
class jinja2.utils.markup . as of jinja 24 this can also
be a callable that is passed the template name and has to
return true or false depending on autoescape should be
enabled by default.

versionchanged 24
autoescape can now be a function

loader
the template loader for this environment.

cache size
the size of the cache. per default this is 400 which means
that if more than 400 templates are loaded the loader will clean
out the least recently used template. if the cache size is set to
0 templates are recompiled all the time, if the cache size is
1 the cache will not be cleaned.

versionchanged 28
the cache size was increased to 400 from a low 50.

auto reload
some loaders load templates from locations where the template
sources may change ie file system or database . if
auto reload is set to true default every time a template is
requested the loader checks if the source changed and if yes, it
will reload the template. for higher performance it s possible to
disable that.

bytecode cache
if set to a bytecode cache object, this object will provide a
cache for the internal jinja bytecode so that templates don t
have to be parsed if they were not changed.

see ref bytecode cache for more information.

enable async
if set to true this enables async template execution which allows
you to take advantage of newer python features. this requires
python 36 or later.","it contains
important shared variables like configuration, filters, tests,
globals and others. instances of this class may be modified if
they are not shared and if no template was loaded so far.
modifications on environments after the first template was loaded
will lead to surprising effects and undefined behavior.",
5,EOF,"raised when eof is read from a child.
this usually means the child has exited.",this usually means the child has exited.,,,,
5,ExceptionPexpect,base class for all exceptions raised by this module.,base class for all exceptions raised by this module.,,,,
5,ExtractError,general exception for extract errors.,general exception for extract errors.,,,,
5,FakeFile,"wrap a list of lines in an object with readline to make
configparser happy.",wrap a list of lines in an object,,,with readline to make configparser happy.,
5,fdspawn,"this is like pexpect.spawn but allows you to supply your own open file
descriptor. for example, you could use it to read through a file looking
for patterns, or to control a modem or serial device.","this is like pexpect.spawn but allows you to supply your own open file
descriptor.","for example, you could use it to read through a file looking
for patterns, or to control a modem or serial device.",,,
5,FileMetadata,"metadata handler for standalone pkg info files

usage

metadata filemetadata path to pkg info

this provider rejects all data and metadata requests except for pkg info,
which is treated as existing, and will be the contents of the file at
the provided location.
metadata handler for standalone pkg info files

usage

metadata filemetadata path to pkg info

this provider rejects all data and metadata requests except for pkg info,
which is treated as existing, and will be the contents of the file at
the provided location.",metadata handler for standalone pkg info files,"usage

metadata filemetadata path to pkg info
usage

metadata filemetadata path to pkg info",,"this provider rejects all data and metadata requests except for pkg info,
which is treated as existing, and will be the contents of the file at
the provided location.
metadata handler for standalone pkg info files

this provider rejects all data and metadata requests except for pkg info,
which is treated as existing, and will be the contents of the file at
the provided location.",
5,FileSystemLoader,"loads templates from the file system. this loader can find templates
in folders on the file system and is the preferred way to load them.

the loader takes the path to the templates as string, or if multiple
locations are wanted a list of them which is then looked up in the
given order

loader filesystemloader path to templates
loader filesystemloader path to templates , other path

per default the template encoding is utf 8 which can be changed
by setting the encoding parameter to something else.

to follow symbolic links, set the followlinks parameter to true

loader filesystemloader path to templates , followlinks true

versionchanged 28
the followlinks parameter was added.","loads templates from the file system. this loader can find templates
in folders on the file system and is the preferred way to load them.","the loader takes the path to the templates as string, or if multiple
locations are wanted a list of them which is then looked up in the
given order

loader filesystemloader path to templates
loader filesystemloader path to templates , other path

per default the template encoding is utf 8 which can be changed
by setting the encoding parameter to something else.

to follow symbolic links, set the followlinks parameter to true",,,
5,Filter,alphabetizes attributes for elements,alphabetizes attributes for elements,,,,
5,Filter_,sanitizes token stream of xhtml mathml svg and of inline style attributes,sanitizes token stream of xhtml mathml svg and of inline style attributes,,,,
5,FollowedBy,"lookahead matching of the given parse expression.
followedby does not advance the parsing position within
the input string, it only verifies that the specified parse
expression matches at the current position. followedby
always returns a null token list. if any results names are defined
in the lookahead expression, those will be returned for access by
name.

example

# use followedby to match a label only if it is followed by a
data word word alphas
label data word followedby
attr expr group label suppress oneormore data word, stopon label .setparseaction .join

oneormore attr expr .parsestring shape square color black posn upper left .pprint

prints

shape , square , color , black , posn , upper left","lookahead matching of the given parse expression.
followedby does not advance the parsing position within
the input string, it only verifies that the specified parse
expression matches at the current position. followedby
always returns a null token list.","followedby does not advance the parsing position within
the input string, it only verifies that the specified parse
expression matches at the current position. followedby
always returns a null token list. if any results names are defined
in the lookahead expression, those will be returned for access by
name.

example

# use followedby to match a label only if it is followed by a
data word word alphas
label data word followedby
attr expr group label suppress oneormore data word, stopon label .setparseaction .join

oneormore attr expr .parsestring shape square color black posn upper left .pprint

prints

shape , square , color , black , posn , upper left",,"if any results names are defined
in the lookahead expression, those will be returned for access by
name.","followedby does not advance the parsing position within
the input string, it only verifies that the specified parse
expression matches at the current position. followedby
always returns a null token list. if any results names are defined
in the lookahead expression, those will be returned for access by
name."
5,Getattr,"get an attribute or item from an expression that is a ascii only
bytestring and prefer the attribute.",,"get an attribute or item from an expression that is a ascii only
bytestring and prefer the attribute.",,,
5,HashMissing,a hash was needed for a requirement but is absent.,a hash was needed for a requirement but is absent.,,,,
5,HebrewProber,"the prober is divided between two sbcharsetprobers and a hebrewprober,
all of which are managed, created, fed data, inquired and deleted by the
sbcsgroupprober. the two sbcharsetprobers identify that the text is in
fact some kind of hebrew, logical or visual. the final decision about which
one is it is made by the hebrewprober by combining final letter scores
with the scores of the two sbcharsetprobers to produce a final answer.
the sbcsgroupprober is responsible for stripping the original text of html
tags, english characters, numbers, low ascii punctuation characters, spaces
and new lines. it reduces any sequence of such characters to a single space.
the buffer fed to each prober in the sbcs group prober is pure text in
high ascii.
the two sbcharsetprobers model probers share the same language model
win1255model.
the first sbcharsetprober uses the model normally as any other
sbcharsetprober does, to recognize windows 1255, upon which this model was
built. the second sbcharsetprober is told to make the pair of letter
lookup in the language model backwards. this in practice exactly simulates
a visual hebrew model using the windows 1255 logical hebrew model.
the hebrewprober is not using any language model. all it does is look for
final letter evidence suggesting the text is either logical hebrew or visual
hebrew. disjointed from the model probers, the results of the hebrewprober
alone are meaningless. hebrewprober always returns 000 as confidence
since it never identifies a charset by itself. instead, the pointer to the
hebrewprober is passed to the model probers as a helper name prober .
when the group prober receives a positive identification from any prober,
it asks for the name of the charset identified. if the prober queried is a
hebrew model prober, the model prober forwards the call to the
hebrewprober to make the final decision. in the hebrewprober, the
decision is made according to the final letters scores maintained and both
model probers scores. the answer is returned in the form of the name of the
charset identified, either windows 1255 or iso 8859 8",it reduces any sequence of such characters to a single space.,"the final decision about which one is it is made by the hebrewprober by combining final letter scores
with the scores of the two sbcharsetprobers to produce a final answer.

the first sbcharsetprober uses the model normally as any other sbcharsetprober does, to recognize windows 1255, upon which this model was
built. the second sbcharsetprober is told to make the pair of letter lookup in the language model backwards.

all it does is look for final letter evidence suggesting the text is either logical hebrew or visual hebrew.

hebrewprober always returns 000 as confidence since it never identifies a charset by itself. instead, the pointer to the hebrewprober is passed to the model probers as a helper name prober .

when the group prober receives a positive identification from any prober, it asks for the name of the charset identified. if the prober queried is a hebrew model prober, the model prober forwards the call to the hebrewprober to make the final decision.

in the hebrewprober, the decision is made according to the final letters scores maintained and both model probers scores. the answer is returned in the form of the name of the charset identified, either windows 1255 or iso 8859 8",,,"the prober is divided between two sbcharsetprobers and a hebrewprober, all of which are managed, created, fed data, inquired and deleted by the sbcsgroupprober.

the two sbcharsetprobers identify that the text is in
fact some kind of hebrew, logical or visual.

the sbcsgroupprober is responsible for stripping the original text of html tags, english characters, numbers, low ascii punctuation characters, spaces and new lines.

the buffer fed to each prober in the sbcs group prober is pure text in high ascii.
the two sbcharsetprobers model probers share the same language model win1255model.

this in practice exactly simulates a visual hebrew model using the windows 1255 logical hebrew model. the hebrewprober is not using any language model.

disjointed from the model probers, the results of the hebrewprober
alone are meaningless."
5,HTMLParser,"html parser

generates a tree structure from a stream of possibly malformed html.","html parser

generates a tree structure from a stream of possibly malformed html.",,,,
5,HTTPError,an http error occurred.,an http error occurred.,,,,
5,InCellPhase,http www.whatwg.org specs web apps current work in cell,,,,,
5,InsecurePlatformWarning,warned when certain ssl configuration is not available on a platform.,warned when certain ssl configuration is not available on a platform.,,,,
5,InspectedValidator,metaclass for all validators,metaclass for all validators,,,,
5,InstalledDistribution,"created with the path of the .dist info directory provided to the
constructor. it reads the metadata contained in pydist.json when it is
instantiated., or uses a passed in metadata instance useful for when
dry run mode is being used .",,"it reads the metadata contained in pydist.json when it is
instantiated., or uses a passed in metadata instance useful for when
dry run mode is being used .",,,created with the path of the .dist info directory provided to the constructor.
5,InternalName,"an internal name in the compiler. you cannot create these nodes
yourself but the parser provides a
meth jinja2.parser.parser.free identifier method that creates
a new identifier for you. this identifier is not available from the
template and is not threated specially by the compiler.",an internal name in the compiler,,,,"you cannot create these nodes
yourself but the parser provides a
meth jinja2.parser.parser.free identifier method that creates
a new identifier for you. this identifier is not available from the
template and is not threated specially by the compiler."
5,InvalidDateError,a date field was improperly specified.,a date field was improperly specified.,,,,
5,InvalidHeaderError,exception for invalid headers.,exception for invalid headers.,,,,
5,InvalidVersion,"an invalid version was found, users should refer to pep 440.","an invalid version was found,",users should refer to pep 440.,,,
5,Kanji,unicode set for kanji unicode character range,unicode set for kanji unicode character range,,,,
5,Katakana,unicode set for katakana unicode character range,unicode set for katakana unicode character range,,,,
5,KeyType,"the type of a key.

keys can be bare unquoted , or quoted using basic , or literal
quotes following the same escaping rules as single line stringtype.",the type of a key.,,"keys can be bare unquoted , or quoted using basic , or literal
quotes following the same escaping rules as single line stringtype.","keys can be bare unquoted , or quoted using basic , or literal
quotes following the same escaping rules as single line stringtype.",
5,LockFailed,"lock file creation failed for some other reason.

try
raise lockfailed
except lockerror
pass",lock file creation failed for some other reason.,"try
raise lockfailed
except lockerror
pass",,,
5,LRUCache,"a simple lru cache implementation.
this is fast for small capacities something below 1000 but doesn t
scale. but as long as it s only used as storage for templates this
won t do any harm.",a simple lru cache implementation.,,,,"this is fast for small capacities something below 1000 but doesn t
scale. but as long as it s only used as storage for templates this
won t do any harm."
5,Markup,"a string that is ready to be safely inserted into an html or xml
document, either because it was escaped or because it was marked
safe.

passing an object to the constructor converts it to text and wraps
it to mark it safe without escaping. to escape the text, use the
meth escape class method instead.

markup hello, em world em !
markup hello, em world em !
markup 42
markup 42
markup.escape hello, em world em !
markup hello &lt em&gt world&lt em&gt !

this implements the html interface that some frameworks
use. passing an object that implements html will wrap the
output of that method, marking it safe.

class foo
def html self
return a href foo foo a

markup foo
markup a href foo foo a

this is a subclass of the text type str in python 3,
unicode in python 2 . it has the same methods as that type, but
all methods escape their arguments and return a markup instance.

markup em %s em % foo & bar
markup em foo &amp bar em
markup em hello em foo
markup em hello em &lt foo&gt","a string that is ready to be safely inserted into an html or xml
document, either because it was escaped or because it was marked
safe.","to escape the text, use the
meth escape class method instead.

markup hello, em world em !
markup hello, em world em !
markup 42
markup 42
markup.escape hello, em world em !
markup hello &lt em&gt world&lt em&gt !
this implements the html interface that some frameworks
use. passing an object that implements html will wrap the
output of that method, marking it safe.

class foo
def html self
return a href foo foo a

markup foo
markup a href foo foo a

this is a subclass of the text type str in python 3,
unicode in python 2 . it has the same methods as that type, but
all methods escape their arguments and return a markup instance.

markup em %s em % foo & bar
markup em foo &amp bar em
markup em hello em foo
markup em hello em &lt foo&gt","passing an object to the constructor converts it to text and wraps
it to mark it safe without escaping. to escape the text, use the
meth escape class method instead.","passing an object to the constructor converts it to text and wraps
it to mark it safe without escaping. to escape the text, use the
meth escape class method instead.","markup hello, em world em !
markup hello, em world em !
markup 42
markup 42
markup.escape hello, em world em !
markup hello &lt em&gt world&lt em&gt !
this implements the html interface that some frameworks
use. passing an object that implements html will wrap the
output of that method, marking it safe.

class foo
def html self
return a href foo foo a

markup foo
markup a href foo foo a

this is a subclass of the text type str in python 3,
unicode in python 2 . it has the same methods as that type, but
all methods escape their arguments and return a markup instance.

markup em %s em % foo & bar
markup em foo &amp bar em
markup em hello em foo
markup em hello em &lt foo&gt"
5,MemcachedBytecodeCache,"this class implements a bytecode cache that uses a memcache cache for
storing the information. it does not enforce a specific memcache library
tummy s memcache or cmemcache but will accept any class that provides
the minimal interface required.

libraries compatible with this class

werkzeug http werkzeug.pocoo.org .contrib.cache
python memcached https www.tummy.com community software python memcached
cmemcache http gijsbert.org cmemcache

unfortunately the django cache interface is not compatible because it
does not support storing binary data, only unicode. you can however pass
the underlying cache client to the bytecode cache which is available
as django.core.cache.cache. client .

the minimal interface for the client passed to the constructor is this

class minimalclientinterface

method set key, value , timeout

stores the bytecode in the cache. value is a string and
timeout the timeout of the key. if timeout is not provided
a default timeout or no timeout should be assumed, if it s
provided it s an integer with the number of seconds the cache
item should exist.

method get key

returns the value for the cache key. if the item does not
exist in the cache the return value must be none .

the other arguments to the constructor are the prefix for all keys that
is added before the actual cache key and the timeout for the bytecode in
the cache system. we recommend a high or no timeout.

this bytecode cache does not support clearing of used items in the cache.
the clear method is a no operation function.

versionadded 27
added support for ignoring memcache errors through the
ignore memcache errors parameter.","this class implements a bytecode cache that uses a memcache cache for
storing the information.","the minimal interface for the client passed to the constructor is this

class minimalclientinterface

method set key, value , timeout

stores the bytecode in the cache. value is a string and
timeout the timeout of the key. if timeout is not provided
a default timeout or no timeout should be assumed, if it s
provided it s an integer with the number of seconds the cache
item should exist.

method get key

returns the value for the cache key. if the item does not
exist in the cache the return value must be none .

the other arguments to the constructor are the prefix for all keys that
is added before the actual cache key and the timeout for the bytecode in
the cache system. we recommend a high or no timeout.",,"it does not enforce a specific memcache library
tummy s memcache or cmemcache but will accept any class that provides
the minimal interface required.",
5,MemoizedZipManifests,memoized zipfile manifests.,memoized zipfile manifests.,,,,
5,MetadataMissingError,a required metadata is missing,a required metadata is missing,,,,
5,MethodDispatcher,"dict with 2 special properties

on initiation, keys that are lists, sets or tuples are converted to
multiple keys so accessing any one of the items in the original
list like object returns the matching value

md methoddispatcher foo , bar baz
md foo baz

a default value which can be set through the default attribute.",dict with 2 special properties,a default value which can be set through the default attribute.,,"on initiation, keys that are lists, sets or tuples are converted to
multiple keys so accessing any one of the items in the original
list like object returns the matching value

md methoddispatcher foo , bar baz md foo baz
a default value which can be set through the default attribute.",
5,Module_six_moves_urllib_parse,lazy loading of moved objects in six.moves.urllib parse,lazy loading of moved objects in six.moves.urllib parse,,,,
5,Module_six_moves_urllib_request,lazy loading of moved objects in six.moves.urllib request,lazy loading of moved objects in six.moves.urllib request,,,,
5,Module_six_moves_urllib_response,lazy loading of moved objects in six.moves.urllib response,lazy loading of moved objects in six.moves.urllib response,,,,
5,Mul,multiplies the left with the right node.,multiplies the left with the right node.,,,,
5,NativeEnvironment,an environment that renders templates to native python types.,an environment that renders templates to native python types.,,,,
5,Node,represents an item in the tree,represents an item in the tree,,,,
5,NoMatch,a token that will never match.,a token that will never match.,,,,
5,NotAny,"lookahead to disallow matching with the given parse expression.
notany does not advance the parsing position within the
input string, it only verifies that the specified parse expression
does not match at the current position. also, notany does
not skip over leading whitespace. notany always returns
a null token list. may be constructed using the operator.

example

and, or, not map caselesskeyword, and or not .split

# take care not to mistake keywords for identifiers
ident and or not word alphas
boolean term optional not ident

# very crude boolean expression to support parenthesis groups and
# operation hierarchy, use infixnotation
boolean expr boolean term zeroormore and or boolean term

# integers that are followed by . are actually floats
integer word nums char .",lookahead to disallow matching with the given parse expression.,"notany always returns
a null token list. may be constructed using the operator.

example

and, or, not map caselesskeyword, and or not .split

# take care not to mistake keywords for identifiers
ident and or not word alphas
boolean term optional not ident

# very crude boolean expression to support parenthesis groups and
# operation hierarchy, use infixnotation
boolean expr boolean term zeroormore and or boolean term

# integers that are followed by . are actually floats
integer word nums char .",,"notany does not advance the parsing position within the
input string, it only verifies that the specified parse expression
does not match at the current position. also, notany does
not skip over leading whitespace.",
5,NotMyLock,"raised when an attempt is made to unlock a file someone else locked.

try
raise notmylock
except unlockerror
pass",raised when an attempt is made to unlock a file someone else locked.,"try
raise notmylock
except unlockerror
pass",,,
5,omdict,"ordered multivalue dictionary.

a multivalue dictionary is a dictionary that can store multiple values per
key. an ordered multivalue dictionary is a multivalue dictionary that
retains the order of insertions and deletions.

internally, items are stored in a doubly linked list, self. items. a
dictionary, self. map, is also maintained and stores an ordered list of
linked list node references, one for each value associated with that key.

standard dict methods interact with the first value associated with a given
key. this means that omdict retains method parity with dict, and a dict
object can be replaced with an omdict object and all interaction will
behave identically. all dict methods that retain parity with omdict are

get , setdefault , pop , popitem ,
clear , copy , update , fromkeys , len
getitem , setitem , delitem , contains ,
items , keys , values , iteritems , iterkeys , itervalues ,

optional parameters have been added to some dict methods, but because the
added parameters are optional, existing use remains unaffected. an optional
key parameter has been added to these methods

items , values , iteritems , itervalues

new methods have also been added to omdict. methods with list in their
name interact with lists of values, and methods with all in their name
interact with all items in the dictionary, including multiple items with
the same key.

the new omdict methods are

load , size , reverse ,
getlist , add , addlist , set , setlist , setdefaultlist ,
poplist , popvalue , popvalues , popitem , poplistitem ,
allitems , allkeys , allvalues , lists , listitems ,
iterallitems , iterallkeys , iterallvalues , iterlists ,
iterlistitems

explanations and examples of the new methods above can be found in the
function comments below and online at

https github.com gruns orderedmultidict

additional omdict information and documentation can also be found at the
above url.","ordered multivalue dictionary.

a multivalue dictionary is a dictionary that can store multiple values per
key. an ordered multivalue dictionary is a multivalue dictionary that
retains the order of insertions and deletions.","get , setdefault , pop , popitem ,
clear , copy , update , fromkeys , len
getitem , setitem , delitem , contains ,
items , keys , values , iteritems , iterkeys , itervalues ,

optional parameters have been added to some dict methods, but because the
added parameters are optional, existing use remains unaffected. an optional
key parameter has been added to these methods

items , values , iteritems , itervalues

new methods have also been added to omdict. methods with list in their
name interact with lists of values, and methods with all in their name
interact with all items in the dictionary, including multiple items with
the same key.

the new omdict methods are

load , size , reverse ,
getlist , add , addlist , set , setlist , setdefaultlist ,
poplist , popvalue , popvalues , popitem , poplistitem ,
allitems , allkeys , allvalues , lists , listitems ,
iterallitems , iterallkeys , iterallvalues , iterlists ,
iterlistitems",,"internally, items are stored in a doubly linked list, self. items. a
dictionary, self. map, is also maintained and stores an ordered list of
linked list node references, one for each value associated with that key.

standard dict methods interact with the first value associated with a given
key. this means that omdict retains method parity with dict, and a dict
object can be replaced with an omdict object and all interaction will
behave identically. all dict methods that retain parity with omdict are",
5,Option,"options are usually optional values on the command line and
have some extra features that arguments don t have.

all other parameters are passed onwards to the parameter constructor.

param show default controls if the default value should be shown on the
help page. normally, defaults are not shown. if this
value is a string, it shows the string instead of the
value. this is particularly useful for dynamic options.
param show envvar controls if an environment variable should be shown on
the help page. normally, environment variables
are not shown.
param prompt if set to true or a non empty string then the user will be
prompted for input. if set to true the prompt will be the
option name capitalized.
param confirmation prompt if set then the value will need to be confirmed
if it was prompted for.
param hide input if this is true then the input on the prompt will be
hidden from the user. this is useful for password
input.
param is flag forces this option to act as a flag. the default is
auto detection.
param flag value which value should be used for this flag if it s
enabled. this is set to a boolean automatically if
the option string contains a slash to mark two options.
param multiple if this is set to true then the argument is accepted
multiple times and recorded. this is similar to nargs
in how it works but supports arbitrary number of
arguments.
param count this flag makes an option increment an integer.
param allow from autoenv if this is enabled then the value of this
parameter will be pulled from an environment
variable in case a prefix is defined on the
context.
param help the help string.
param hidden hide this option from help outputs.","options are usually optional values on the command line and
have some extra features that arguments don t have.",all other parameters are passed onwards to the parameter constructor.,"param show default controls if the default value should be shown on the
help page. normally, defaults are not shown. if this
value is a string, it shows the string instead of the
value. this is particularly useful for dynamic options.
param show envvar controls if an environment variable should be shown on
the help page. normally, environment variables
are not shown.
param prompt if set to true or a non empty string then the user will be
prompted for input. if set to true the prompt will be the
option name capitalized.
param confirmation prompt if set then the value will need to be confirmed
if it was prompted for.
param hide input if this is true then the input on the prompt will be
hidden from the user. this is useful for password
input.
param is flag forces this option to act as a flag. the default is
auto detection.
param flag value which value should be used for this flag if it s
enabled. this is set to a boolean automatically if
the option string contains a slash to mark two options.
param multiple if this is set to true then the argument is accepted
multiple times and recorded. this is similar to nargs
in how it works but supports arbitrary number of
arguments.
param count this flag makes an option increment an integer.
param allow from autoenv if this is enabled then the value of this
parameter will be pulled from an environment
variable in case a prefix is defined on the
context.
param help the help string.
param hidden hide this option from help outputs.",,
5,PacifyFlushWrapper,"this wrapper is used to catch and suppress brokenpipeerrors resulting
from .flush being called on broken pipe during the shutdown final gc
of the python interpreter. notably .flush is always called on
sys.stdout and sys.stderr . so as to have minimal impact on any
other cleanup code, and the case where the underlying file is not a broken
pipe, all calls and attributes are proxied.","this wrapper is used to catch and suppress brokenpipeerrors resulting
from .flush being called on broken pipe during the shutdown final gc
of the python interpreter.",,,"this wrapper is used to catch and suppress brokenpipeerrors resulting
from .flush being called on broken pipe during the shutdown final gc
of the python interpreter.

notably .flush is always called on
sys.stdout and sys.stderr . so as to have minimal impact on any
other cleanup code, and the case where the underlying file is not a broken
pipe, all calls and attributes are proxied.",
5,PackageIndex,represents a package index and provides easier access to endpoints,represents a package index and provides easier access to endpoints,,,,
5,ParseError,"this error occurs when the parser encounters a syntax error
in the toml being parsed. the error references the line and
location within the line where the error was encountered.","this error occurs when the parser encounters a syntax error
in the toml being parsed.",,,the error references the line and location within the line where the error was encountered.,
5,ParseFatalException,"user throwable exception thrown when inconsistent parse content
is found stops all parsing immediately",,,,,"user throwable exception thrown when inconsistent parse content
is found stops all parsing immediately"
5,ParserElement,abstract base level parser element class.,abstract base level parser element class.,,,,
5,ParseResultBytes,compatibility shim for the urlparse.parseresultbytes object.,compatibility shim for the urlparse.parseresultbytes object.,,,,
5,ParseResults,"structured parse results, to provide multiple means of access to
the parsed data

as a list len results
by list index results 0 , results 1 , etc
by attribute results. resultsname see class parserelement.setresultsname

example

integer word nums
date str integer.setresultsname year
integer.setresultsname month
integer.setresultsname day
# equivalent form
# date str integer year integer month integer day

# parsestring returns a parseresults object
result date str.parsestring 1999 12 31

def test s, fn repr
print %s %s % s, fn eval s
test list result
test result 0
test result month
test result.day
test month in result
test minutes in result
test result.dump , str

prints

list result 1999 , , 12 , , 31
result 0 1999
result month 12
result.day 31
month in result true
minutes in result false
result.dump 1999 , , 12 , , 31
day 31
month 12
year 1999","structured parse results, to provide multiple means of access to
the parsed data","the parsed data

as a list len results
by list index results 0 , results 1 , etc
by attribute results. resultsname see class parserelement.setresultsname

example

integer word nums
date str integer.setresultsname year
integer.setresultsname month
integer.setresultsname day
# equivalent form
# date str integer year integer month integer day

# parsestring returns a parseresults object
result date str.parsestring 1999 12 31

def test s, fn repr
print %s %s % s, fn eval s
test list result
test result 0
test result month
test result.day
test month in result
test minutes in result
test result.dump , str

prints

list result 1999 , , 12 , , 31
result 0 1999
result month 12
result.day 31
month in result true
minutes in result false
result.dump 1999 , , 12 , , 31
day 31
month 12
year 1999",,,"example

integer word nums
date str integer.setresultsname year
integer.setresultsname month
integer.setresultsname day
# equivalent form
# date str integer year integer month integer day

# parsestring returns a parseresults object
result date str.parsestring 1999 12 31

def test s, fn repr
print %s %s % s, fn eval s
test list result
test result 0
test result month
test result.day
test month in result
test minutes in result
test result.dump , str"
5,ParseSyntaxException,"just like class parsefatalexception , but thrown internally
when an class errorstop and. errorstop operator indicates
that parsing is to stop immediately because an unbacktrackable
syntax error has been found.",,,,,
5,Path,"the path type is similar to the class file type but it performs
different checks. first of all, instead of returning an open file
handle it returns just the filename. secondly, it can perform various
basic checks about what the file or directory should be.

versionchanged 60
allow dash was added.

param exists if set to true, the file or directory needs to exist for
this value to be valid. if this is not required and a
file does indeed not exist, then all further checks are
silently skipped.
param file okay controls if a file is a possible value.
param dir okay controls if a directory is a possible value.
param writable if true, a writable check is performed.
param readable if true, a readable check is performed.
param resolve path if this is true, then the path is fully resolved
before the value is passed onwards. this means
that it s absolute and symlinks are resolved. it
will not expand a tilde prefix, as this is
supposed to be done by the shell only.
param allow dash if this is set to true , a single dash to indicate
standard streams is permitted.
param path type optionally a string type that should be used to
represent the path. the default is none which
means the return value will be either bytes or
unicode depending on what makes most sense given the
input data click deals with.","the path type is similar to the class file type but it performs
different checks.",,"param exists if set to true, the file or directory needs to exist for
this value to be valid. if this is not required and a
file does indeed not exist, then all further checks are
silently skipped.
param file okay controls if a file is a possible value.
param dir okay controls if a directory is a possible value.
param writable if true, a writable check is performed.
param readable if true, a readable check is performed.
param resolve path if this is true, then the path is fully resolved
before the value is passed onwards. this means
that it s absolute and symlinks are resolved. it
will not expand a tilde prefix, as this is
supposed to be done by the shell only.
param allow dash if this is set to true , a single dash to indicate
standard streams is permitted.
param path type optionally a string type that should be used to
represent the path. the default is none which
means the return value will be either bytes or
unicode depending on what makes most sense given the
input data click deals with.",,"first of all, instead of returning an open file
handle it returns just the filename. secondly, it can perform various
basic checks about what the file or directory should be."
5,PipError,base pip exception,base pip exception,,,,
5,PoolManager,"allows for arbitrary requests while transparently keeping track of
necessary connection pools for you.

param num pools
number of connection pools to cache before discarding the least
recently used pool.

param headers
headers to include with all requests, unless other headers are given
explicitly.

param connection pool kw
additional parameters are used to create fresh
class urllib3.connectionpool.connectionpool instances.

example

manager poolmanager num pools 2
r manager.request get , http google.com
r manager.request get , http google.com mail
r manager.request get , http yahoo.com
len manager.pools","allows for arbitrary requests while transparently keeping track of
necessary connection pools for you.","example

manager poolmanager num pools 2
r manager.request get , http google.com
r manager.request get , http google.com mail
r manager.request get , http yahoo.com
len manager.pools","param num pools
number of connection pools to cache before discarding the least
recently used pool.

param headers
headers to include with all requests, unless other headers are given
explicitly.

param connection pool kw
additional parameters are used to create fresh
class urllib3.connectionpool.connectionpool instances.",,
5,PrefixLoader,"a loader that is passed a dict of loaders where each loader is bound
to a prefix. the prefix is delimited from the template by a slash per
default, which can be changed by setting the delimiter argument to
something else

loader prefixloader
app1 packageloader mypackage.app1 ,
app2 packageloader mypackage.app2

by loading app1 index.html the file from the app1 package is loaded,
by loading app2 index.html the file from the second.","a loader that is passed a dict of loaders where each loader is bound
to a prefix.","the prefix is delimited from the template by a slash per
default, which can be changed by setting the delimiter argument to
something else

loader prefixloader
app1 packageloader mypackage.app1 ,
app2 packageloader mypackage.app2

by loading app1 index.html the file from the app1 package is loaded,
by loading app2 index.html the file from the second.",,"the prefix is delimited from the template by a slash per
default, which can be changed by setting the delimiter argument to
something else",
5,ProcessedTraceback,holds a jinja preprocessed traceback for printing or reraising.,holds a jinja preprocessed traceback for printing or reraising.,,,,
5,PyPIJSONLocator,"this locator uses pypi s json interface. it s very limited in functionality
and probably not worth using.",,,,this locator uses pypi s json interface.,
5,ReadError,raised when an archive cannot be read,raised when an archive cannot be read,,,,
5,Request,"a user created class request request object.

used to prepare a class preparedrequest preparedrequest , which is sent to the server.

param method http method to use.
param url url to send.
param headers dictionary of headers to send.
param files dictionary of filename fileobject files to multipart upload.
param data the body to attach to the request. if a dictionary or
list of tuples key, value is provided, form encoding will
take place.
param json json for the body to attach to the request if files or data is not specified .
param params url parameters to append to the url. if a dictionary or
list of tuples key, value is provided, form encoding will
take place.
param auth auth handler or user, pass tuple.
param cookies dictionary or cookiejar of cookies to attach to this request.
param hooks dictionary of callback hooks, for internal usage.

usage

import requests
req requests.request get , https httpbin.org get
req.prepare
preparedrequest get",a user created class request request object.,"usage

import requests
req requests.request get , https httpbin.org get
req.prepare
preparedrequest get","param method http method to use.
param url url to send.
param headers dictionary of headers to send.
param files dictionary of filename fileobject files to multipart upload.
param data the body to attach to the request. if a dictionary or
list of tuples key, value is provided, form encoding will
take place.
param json json for the body to attach to the request if files or data is not specified .
param params url parameters to append to the url. if a dictionary or
list of tuples key, value is provided, form encoding will
take place.
param auth auth handler or user, pass tuple.
param cookies dictionary or cookiejar of cookies to attach to this request.
param hooks dictionary of callback hooks, for internal usage.",,"used to prepare a class preparedrequest preparedrequest , which is sent to the server."
5,RequestException,"there was an ambiguous exception that occurred while handling your
request.",,,,,
5,RequirementsFileParseError,raised when a general error occurs parsing a requirements file line.,raised when a general error occurs parsing a requirements file line.,,,,
5,RequirementUninstaller,"a context manager to remove a package for the inner block.

this uses uninstallpathset to control the workflow. if the inner block
exits correctly, the uninstallation is committed, otherwise rolled back.",a context manager to remove a package for the inner block.,,,"this uses uninstallpathset to control the workflow. if the inner block
exits correctly, the uninstallation is committed, otherwise rolled back.",
5,RequiresPythonCache,cache a candidate s requires python information.,cache a candidate s requires python information.,,,,
5,Resource,"a class representing an in package resource, such as a data file. this is
not normally instantiated by user code, but rather by a
class resourcefinder which manages the resource.","a class representing an in package resource, such as a data file.",,,,"this is
not normally instantiated by user code, but rather by a
class resourcefinder which manages the resource."
5,ResourceFinder,resource finder for file system resources.,resource finder for file system resources.,,,,
5,ResourceManager,manage resource extraction and packages,manage resource extraction and packages,,,,
5,ResponseError,used as a container for an error reason supplied in a maxretryerror.,,used as a container for an error reason supplied in a maxretryerror.,,,
5,ResponseNotChunked,response needs to be chunked in order to read it as chunks.,,response needs to be chunked in order to read it as chunks.,,,
5,Retry,"retry configuration.

each retry attempt will create a new retry object with updated values, so
they can be safely reused.

retries can be defined as a default for a pool

retries retry connect 5, read 2, redirect 5
http poolmanager retries retries
response http.request get , http example.com

or per request which overrides the default for the pool

response http.request get , http example.com , retries retry 10

retries can be disabled by passing false

response http.request get , http example.com , retries false

errors will be wrapped in class urllib3.exceptions.maxretryerror unless
retries are disabled, in which case the causing exception will be raised.

param int total
total number of retries to allow. takes precedence over other counts.

set to none to remove this constraint and fall back on other
counts. it s a good idea to set this to some sensibly high value to
account for unexpected edge cases and avoid infinite retry loops.

set to 0 to fail on the first retry.

set to false to disable and imply raise on redirect false .

param int connect
how many connection related errors to retry on.

these are errors raised before the request is sent to the remote server,
which we assume has not triggered the server to process the request.

set to 0 to fail on the first retry of this type.

param int read
how many times to retry on read errors.

these errors are raised after the request was sent to the server, so the
request may have side effects.

set to 0 to fail on the first retry of this type.

param int redirect
how many redirects to perform. limit this to avoid infinite redirect
loops.

a redirect is a http response with a status code 301, 302, 303, 307 or
308.

set to 0 to fail on the first retry of this type.

set to false to disable and imply raise on redirect false .

param int status
how many times to retry on bad status codes.

these are retries made on responses, where status code matches
status forcelist .

set to 0 to fail on the first retry of this type.

param iterable method whitelist
set of uppercased http method verbs that we should retry on.

by default, we only retry on methods which are considered to be
idempotent multiple requests with the same parameters end with the
same state . see attr retry.default method whitelist .

set to a false value to retry on any verb.

param iterable status forcelist
a set of integer http status codes that we should force a retry on.
a retry is initiated if the request method is in method whitelist
and the response status code is in status forcelist .

by default, this is disabled with none .

param float backoff factor
a backoff factor to apply between attempts after the second try
most errors are resolved immediately by a second try without a
delay . urllib3 will sleep for

backoff factor 2 number of total retries 1

seconds. if the backoff factor is 01, then func .sleep will sleep
for 00s, 02s, 04s, ... between retries. it will never be longer
than attr retry.backoff max .

by default, backoff is disabled set to 0 .

param bool raise on redirect whether, if the number of redirects is
exhausted, to raise a maxretryerror, or to return a response with a
response code in the 3xx range.

param bool raise on status similar meaning to raise on redirect
whether we should raise an exception, or return a response,
if status falls in status forcelist range and retries have
been exhausted.

param tuple history the history of the request encountered during
each call to meth retry.increment . the list is in the order
the requests occurred. each list item is of class class requesthistory .

param bool respect retry after header
whether to respect retry after header on status codes defined as
attr retry.retry after status codes or not.

param iterable remove headers on redirect
sequence of headers to remove from the request when a response
indicating a redirect is returned before firing off the redirected
request.",retry configuration.,"retries can be defined as a default for a pool

retries retry connect 5, read 2, redirect 5
http poolmanager retries retries
response http.request get , http example.com

or per request which overrides the default for the pool

response http.request get , http example.com , retries retry 10

retries can be disabled by passing false

response http.request get , http example.com , retries false","param int total
total number of retries to allow. takes precedence over other counts.

set to none to remove this constraint and fall back on other
counts. it s a good idea to set this to some sensibly high value to
account for unexpected edge cases and avoid infinite retry loops.

set to 0 to fail on the first retry.

set to false to disable and imply raise on redirect false .

param int connect
how many connection related errors to retry on.

these are errors raised before the request is sent to the remote server,
which we assume has not triggered the server to process the request.

set to 0 to fail on the first retry of this type.

param int read
how many times to retry on read errors.

these errors are raised after the request was sent to the server, so the
request may have side effects.

set to 0 to fail on the first retry of this type.

param int redirect
how many redirects to perform. limit this to avoid infinite redirect
loops.

a redirect is a http response with a status code 301, 302, 303, 307 or
308.

set to 0 to fail on the first retry of this type.

set to false to disable and imply raise on redirect false .

param int status
how many times to retry on bad status codes.

these are retries made on responses, where status code matches
status forcelist .

set to 0 to fail on the first retry of this type.

param iterable method whitelist
set of uppercased http method verbs that we should retry on.

by default, we only retry on methods which are considered to be
idempotent multiple requests with the same parameters end with the
same state . see attr retry.default method whitelist .

set to a false value to retry on any verb.

param iterable status forcelist
a set of integer http status codes that we should force a retry on.
a retry is initiated if the request method is in method whitelist
and the response status code is in status forcelist .

by default, this is disabled with none .

param float backoff factor
a backoff factor to apply between attempts after the second try
most errors are resolved immediately by a second try without a
delay . urllib3 will sleep for

backoff factor 2 number of total retries 1

seconds. if the backoff factor is 01, then func .sleep will sleep
for 00s, 02s, 04s, ... between retries. it will never be longer
than attr retry.backoff max .

by default, backoff is disabled set to 0 .

param bool raise on redirect whether, if the number of redirects is
exhausted, to raise a maxretryerror, or to return a response with a
response code in the 3xx range.

param bool raise on status similar meaning to raise on redirect
whether we should raise an exception, or return a response,
if status falls in status forcelist range and retries have
been exhausted.

param tuple history the history of the request encountered during
each call to meth retry.increment . the list is in the order
the requests occurred. each list item is of class class requesthistory .

param bool respect retry after header
whether to respect retry after header on status codes defined as
attr retry.retry after status codes or not.

param iterable remove headers on redirect
sequence of headers to remove from the request when a response
indicating a redirect is returned before firing off the redirected
request.","each retry attempt will create a new retry object with updated values, so
they can be safely reused.",
5,SafeFileCache,"a file based cache which is safe to use even when the target directory may
not be accessible or writable.","a file based cache which is safe to use even when the target directory may
not be accessible or writable.",,,,
5,SchemaValidatorMixin,"this validator mixin provides mechanics to validate schemas passed to a cerberus
validator.","this validator mixin provides mechanics to validate schemas passed to a cerberus
validator.",,,,
5,Session,"a requests session.

provides cookie persistence, connection pooling, and configuration.

basic usage

import requests
s requests.session
s.get https httpbin.org get
response 200

or as a context manager

with requests.session as s
s.get https httpbin.org get
response 200","a requests session.

provides cookie persistence, connection pooling, and configuration.","basic usage

import requests
s requests.session
s.get https httpbin.org get
response 200

or as a context manager

with requests.session as s
s.get https httpbin.org get
response 200",,,
5,SkipTo,"token for skipping over all undefined text until the matched
expression is found.

parameters
expr target expression marking the end of the data to be skipped
include default false if true, the target expression is also parsed
the skipped text and target expression are returned as a 2 element list .
ignore default none used to define grammars typically quoted strings and
comments that might contain false matches to the target expression
failon default none define expressions that are not allowed to be
included in the skipped test if found before the target expression is found,
the skipto is not a match

example

report
outstanding issues report 1 jan 2000

# severity description days open

101 critical intermittent system crash 6
94 cosmetic spelling error on login log n 14
79 minor system slow when running too many reports 47

integer word nums
sep suppress
# use skipto to simply match everything up until the next sep
# ignore quoted strings, so that a character inside a quoted string does not match
# parse action will call token.strip for each matched token, ie, the description body
string data skipto sep, ignore quotedstring
string data.setparseaction tokenmap str.strip
ticket expr integer issue num sep
string data sev sep
string data desc sep
integer days open

for tkt in ticket expr.searchstring report
print tkt.dump

prints

101 , critical , intermittent system crash , 6
days open 6
desc intermittent system crash
issue num 101
sev critical
94 , cosmetic , spelling error on login log n , 14
days open 14
desc spelling error on login log n
issue num 94
sev cosmetic
79 , minor , system slow when running too many reports , 47
days open 47
desc system slow when running too many reports
issue num 79
sev minor","token for skipping over all undefined text until the matched
expression is found.","example

report
outstanding issues report 1 jan 2000

# severity description days open

101 critical intermittent system crash 6
94 cosmetic spelling error on login log n 14
79 minor system slow when running too many reports 47

integer word nums
sep suppress
# use skipto to simply match everything up until the next sep
# ignore quoted strings, so that a character inside a quoted string does not match
# parse action will call token.strip for each matched token, ie, the description body
string data skipto sep, ignore quotedstring
string data.setparseaction tokenmap str.strip
ticket expr integer issue num sep
string data sev sep
string data desc sep
integer days open

for tkt in ticket expr.searchstring report
print tkt.dump

prints

101 , critical , intermittent system crash , 6
days open 6
desc intermittent system crash
issue num 101
sev critical
94 , cosmetic , spelling error on login log n , 14
days open 14
desc spelling error on login log n
issue num 94
sev cosmetic
79 , minor , system slow when running too many reports , 47
days open 47
desc system slow when running too many reports
issue num 79
sev minor","parameters
expr target expression marking the end of the data to be skipped
include default false if true, the target expression is also parsed
the skipped text and target expression are returned as a 2 element list .
ignore default none used to define grammars typically quoted strings and
comments that might contain false matches to the target expression
failon default none define expressions that are not allowed to be
included in the skipped test if found before the target expression is found,
the skipto is not a match",,
5,TarFile,the tarfile class provides an interface to tar archives.,the tarfile class provides an interface to tar archives.,,,,
5,Token,token class.,token class.,,,,
5,TokenStreamIterator,"the iterator for tokenstreams. iterate over the stream
until the eof token is reached.",the iterator for tokenstreams.,,,"iterate over the stream
until the eof token is reached.",
5,TreeBuilder,"base treebuilder implementation

documentclass the class to use for the bottommost node of a document
elementclass the class to use for html elements
commentclass the class to use for comments
doctypeclass the class to use for doctypes",base treebuilder implementation,"documentclass the class to use for the bottommost node of a document
elementclass the class to use for html elements
commentclass the class to use for comments
doctypeclass the class to use for doctypes",,,
5,Trie,abstract base class for tries,abstract base class for tries,,,,
5,UndefinedEnvironmentName,"a name was attempted to be used that does not exist inside of the
environment.","a name was attempted to be used that does not exist inside of the
environment.",,,,
5,UnlockError,"base class for errors arising from attempts to release the lock.

try
raise unlockerror
except error
pass",base class for errors arising from attempts to release the lock.,"try
raise unlockerror
except error
pass",,,
5,ZipResourceFinder,resource finder for resources in .zip files.,resource finder for resources in .zip files.,,,,
6,_OpNamespace,"an op namespace to dynamically bind operators into python.

say a user has created a custom operator called my namespace my op . to
call this op, the user will write torch.ops.my namespace.my op ... .
at startup, this operation will not yet be bound into python. instead, the
following sequence of magic tricks will occur
1. torch.ops.my namespace will invoke the getattr magic method
on the torch.ops object, which will create a new opnamespace
object called my namespace and set it as an attribute on the ops
object.
2. torch.ops.my namespace.my op will then invoke getattr on
the my namespace object, which will retrieve the operation via
torch.get operation , a function bound from c , and then in a similar
fashion bind this new object onto the my namespace object.
3. torch.ops.my namespace.my op ... then calls this new operation
and subsequent accesses will incur no further lookup the namespace and
operation will already exist .",an op namespace to dynamically bind operators into python.,"say a user has created a custom operator called my namespace my op . to
call this op, the user will write torch.ops.my namespace.my op ... .
at startup, this operation will not yet be bound into python. instead, the
following sequence of magic tricks will occur
1. torch.ops.my namespace will invoke the getattr magic method
on the torch.ops object, which will create a new opnamespace
object called my namespace and set it as an attribute on the ops
object.
2. torch.ops.my namespace.my op will then invoke getattr on
the my namespace object, which will retrieve the operation via
torch.get operation , a function bound from c , and then in a similar
fashion bind this new object onto the my namespace object.
3. torch.ops.my namespace.my op ... then calls this new operation
and subsequent accesses will incur no further lookup the namespace and
operation will already exist .",,,"say a user has created a custom operator called my namespace my op . to
call this op, the user will write torch.ops.my namespace.my op ... .
at startup, this operation will not yet be bound into python. instead, the
following sequence of magic tricks will occur
1. torch.ops.my namespace will invoke the getattr magic method
on the torch.ops object, which will create a new opnamespace
object called my namespace and set it as an attribute on the ops
object.
2. torch.ops.my namespace.my op will then invoke getattr on
the my namespace object, which will retrieve the operation via
torch.get operation , a function bound from c , and then in a similar
fashion bind this new object onto the my namespace object.
3. torch.ops.my namespace.my op ... then calls this new operation
and subsequent accesses will incur no further lookup the namespace and
operation will already exist ."
6,Adadelta,"implements adadelta algorithm.

it has been proposed in adadelta an adaptive learning rate method .

arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
rho float, optional coefficient used for computing a running average
of squared gradients default 09
eps float, optional term added to the denominator to improve
numerical stability default 1e 6
lr float, optional coefficient that scale delta before it is applied
to the parameters default 10
weight decay float, optional weight decay l2 penalty default 0

https arxiv.org abs 12125701","implements adadelta algorithm.

it has been proposed in adadelta an adaptive learning rate method",,"arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
rho float, optional coefficient used for computing a running average
of squared gradients default 09
eps float, optional term added to the denominator to improve
numerical stability default 1e 6
lr float, optional coefficient that scale delta before it is applied
to the parameters default 10
weight decay float, optional weight decay l2 penalty default 0",,
6,Adam,"implements adam algorithm.

it has been proposed in adam a method for stochastic optimization .

arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float, optional learning rate default 1e 3
betas tuple float, float , optional coefficients used for computing
running averages of gradient and its square default 09, 0999
eps float, optional term added to the denominator to improve
numerical stability default 1e 8
weight decay float, optional weight decay l2 penalty default 0
amsgrad boolean, optional whether to use the amsgrad variant of this
algorithm from the paper on the convergence of adam and beyond
default false

adam a method for stochastic optimization
https arxiv.org abs 14126980
on the convergence of adam and beyond
https openreview.net forum?id ryqu7f rz",implements adam algorithm.,,"arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float, optional learning rate default 1e 3
betas tuple float, float , optional coefficients used for computing
running averages of gradient and its square default 09, 0999
eps float, optional term added to the denominator to improve
numerical stability default 1e 8
weight decay float, optional weight decay l2 penalty default 0
amsgrad boolean, optional whether to use the amsgrad variant of this
algorithm from the paper on the convergence of adam and beyond
default false",,"it has been proposed in adam a method for stochastic optimization .

adam a method for stochastic optimization
https arxiv.org abs 14126980
on the convergence of adam and beyond
https openreview.net forum?id ryqu7f rz"
6,Adamax,"implements adamax algorithm a variant of adam based on infinity norm .

it has been proposed in adam a method for stochastic optimization .

arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float, optional learning rate default 2e 3
betas tuple float, float , optional coefficients used for computing
running averages of gradient and its square
eps float, optional term added to the denominator to improve
numerical stability default 1e 8
weight decay float, optional weight decay l2 penalty default 0

https arxiv.org abs 14126980","implements adamax algorithm a variant of adam based on infinity norm .
it has been proposed in adam a method for stochastic optimization .",,"arguments
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float, optional learning rate default 2e 3
betas tuple float, float , optional coefficients used for computing
running averages of gradient and its square
eps float, optional term added to the denominator to improve
numerical stability default 1e 8
weight decay float, optional weight decay l2 penalty default 0",,
6,AdaptiveMaxPool3d,"applies a 3d adaptive max pooling over an input signal composed of several input planes.

the output is of size d x h x w, for any input size.
the number of output features is equal to the number of input planes.

args
output size the target output size of the image of the form d x h x w.
can be a tuple d, h, w or a single d for a cube d x d x d.
d, h and w can be either a int , or none which means the size will
be the same as that of the input.

return indices if true , will return the indices along with the outputs.
useful to pass to nn.maxunpool3d. default false

examples
# target output size of 5x7x9
m nn.adaptivemaxpool3d 5,7,9
input torch.randn 1, 64, 8, 9, 10
output m input
# target output size of 7x7x7 cube
m nn.adaptivemaxpool3d 7
input torch.randn 1, 64, 10, 9, 8
output m input
# target output size of 7x9x8
m nn.adaptivemaxpool3d 7, none, none
input torch.randn 1, 64, 10, 9, 8
output m input",applies a 3d adaptive max pooling over an input signal composed of several input planes.,"examples
# target output size of 5x7x9
m nn.adaptivemaxpool3d 5,7,9
input torch.randn 1, 64, 8, 9, 10
output m input
# target output size of 7x7x7 cube
m nn.adaptivemaxpool3d 7
input torch.randn 1, 64, 10, 9, 8
output m input
# target output size of 7x9x8
m nn.adaptivemaxpool3d 7, none, none
input torch.randn 1, 64, 10, 9, 8
output m input","args
output size the target output size of the image of the form d x h x w.
can be a tuple d, h, w or a single d for a cube d x d x d.
d, h and w can be either a int , or none which means the size will
be the same as that of the input.

return indices if true , will return the indices along with the outputs.
useful to pass to nn.maxunpool3d. default false","the output is of size d x h x w, for any input size.
the number of output features is equal to the number of input planes.",
6,BaseTestCase,base class used for all tensorboard tests,base class used for all tensorboard tests,,,,
6,BatchNorm1d,"applies batch normalization over a 2d or 3d input a mini batch of 1d
inputs with optional additional channel dimension as described in the paper
batch normalization accelerating deep network training by reducing internal covariate shift .

math

y frac x mathrm e x sqrt mathrm var x epsilon gamma beta

the mean and standard deviation are calculated per dimension over
the mini batches and math gamma and math beta are learnable parameter vectors
of size c where c is the input size . by default, the elements of math gamma are set
to 1 and the elements of math beta are set to 0.

also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. the running estimates are kept with a default attr momentum
of 01.

if attr track running stats is set to false , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.

note
this attr momentum argument is different from one used in optimizer
classes and the conventional notion of momentum. mathematically, the
update rule for running statistics here is
math hat x text new 1 text momentum times hat x text momentum times x t ,
where math hat x is the estimated statistic and math x t is the
new observed value.

because the batch normalization is done over the c dimension, computing statistics
on n, l slices, it s common terminology to call this temporal batch normalization.

args
num features math c from an expected input of size
math n, c, l or math l from input of size math n, l
eps a value added to the denominator for numerical stability.
default 1e 5
momentum the value used for the running mean and running var
computation. can be set to none for cumulative moving average
ie simple average . default 01
affine a boolean value that when set to true , this module has
learnable affine parameters. default true
track running stats a boolean value that when set to true , this
module tracks the running mean and variance, and when set to false ,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. default true

shape
input math n, c or math n, c, l
output math n, c or math n, c, l same shape as input

examples

# with learnable parameters
m nn.batchnorm1d 100
# without learnable parameters
m nn.batchnorm1d 100, affine false
input torch.randn 20, 100
output m input

batch normalization accelerating deep network training by reducing internal covariate shift
https arxiv.org abs 150203167","applies batch normalization over a 2d or 3d input a mini batch of 1d
inputs with optional additional channel dimension as described in the paper
batch normalization accelerating deep network training by reducing internal covariate shift .","examples

# with learnable parameters
m nn.batchnorm1d 100
# without learnable parameters
m nn.batchnorm1d 100, affine false
input torch.randn 20, 100
output m input","args
num features math c from an expected input of size
math n, c, l or math l from input of size math n, l
eps a value added to the denominator for numerical stability.
default 1e 5
momentum the value used for the running mean and running var
computation. can be set to none for cumulative moving average
ie simple average . default 01
affine a boolean value that when set to true , this module has
learnable affine parameters. default true
track running stats a boolean value that when set to true , this
module tracks the running mean and variance, and when set to false ,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. default true","math

y frac x mathrm e x sqrt mathrm var x epsilon gamma beta

the mean and standard deviation are calculated per dimension over
the mini batches and math gamma and math beta are learnable parameter vectors
of size c where c is the input size . by default, the elements of math gamma are set
to 1 and the elements of math beta are set to 0.

also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. the running estimates are kept with a default attr momentum
of 01.

if attr track running stats is set to false , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.
shape
input math n, c or math n, c, l
output math n, c or math n, c, l same shape as input","note
this attr momentum argument is different from one used in optimizer
classes and the conventional notion of momentum. mathematically, the
update rule for running statistics here is
math hat x text new 1 text momentum times hat x text momentum times x t ,
where math hat x is the estimated statistic and math x t is the
new observed value.

because the batch normalization is done over the c dimension, computing statistics
on n, l slices, it s common terminology to call this temporal batch normalization."
6,BCEWithLogitsLoss,"this loss combines a sigmoid layer and the bceloss in one single
class. this version is more numerically stable than using a plain sigmoid
followed by a bceloss as, by combining the operations into one layer,
we take advantage of the log sum exp trick for numerical stability.

the unreduced ie with attr reduction set to none loss can be described as

math
ell x, y l l 1, dots,l n ^ top, quad
l n w n left y n cdot log sigma x n
1 y n cdot log 1 sigma x n right ,

where math n is the batch size. if attr reduction is not none
default mean , then

math
ell x, y begin cases
operatorname mean l , & text if reduction text mean
operatorname sum l , & text if reduction text sum .
end cases

this is used for measuring the error of a reconstruction in for example
an auto encoder. note that the targets t i should be numbers
between 0 and 1.

it s possible to trade off recall and precision by adding weights to positive examples.
in the case of multi label classification the loss can be described as

math
ell c x, y l c l 1,c , dots,l n,c ^ top, quad
l n,c w n,c left p c y n,c cdot log sigma x n,c
1 y n,c cdot log 1 sigma x n,c right ,

where math c is the class number math c 1 for multi label binary classification,
math c 1 for single label binary classification ,
math n is the number of the sample in the batch and
math p c is the weight of the positive answer for the class math c .

math p c 1 increases the recall, math p c 1 increases the precision.

for example, if a dataset contains 100 positive and 300 negative examples of a single class,
then pos weight for the class should be equal to math frac 300 100 3 .
the loss would act as if the dataset contains math 3 times 100 300 positive examples.

examples

target torch.ones 10, 64 , dtype torch.float32 # 64 classes, batch size 10
output torch.full 10, 64 , 0999 # a prediction logit
pos weight torch.ones 64 # all weights are equal to 1
criterion torch.nn.bcewithlogitsloss pos weight pos weight
criterion output, target # log sigmoid 0999
tensor 03135

args
weight tensor, optional a manual rescaling weight given to the loss
of each batch element. if given, has to be a tensor of size nbatch .
size average bool, optional deprecated see attr reduction . by default,
the losses are averaged over each loss element in the batch. note that for
some losses, there are multiple elements per sample. if the field attr size average
is set to false , the losses are instead summed for each minibatch. ignored
when reduce is false . default true
reduce bool, optional deprecated see attr reduction . by default, the
losses are averaged or summed over observations for each minibatch depending
on attr size average . when attr reduce is false , returns a loss per
batch element instead and ignores attr size average . default true
reduction string, optional specifies the reduction to apply to the output
none mean sum . none no reduction will be applied,
mean the sum of the output will be divided by the number of
elements in the output, sum the output will be summed. note attr size average
and attr reduce are in the process of being deprecated, and in the meantime,
specifying either of those two args will override attr reduction . default mean
pos weight tensor, optional a weight of positive examples.
must be a vector with length equal to the number of classes.

shape
input math n, where math means, any number of additional dimensions
target math n, , same shape as the input
output scalar. if attr reduction is none , then math n, , same
shape as input.

examples

loss nn.bcewithlogitsloss
input torch.randn 3, requires grad true
target torch.empty 3 .random 2
output loss input, target
output.backward","this loss combines a sigmoid layer and the bceloss in one single
class. this version is more numerically stable than using a plain sigmoid
followed by a bceloss as, by combining the operations into one layer,
we take advantage of the log sum exp trick for numerical stability.","examples

target torch.ones 10, 64 , dtype torch.float32 # 64 classes, batch size 10
output torch.full 10, 64 , 0999 # a prediction logit
pos weight torch.ones 64 # all weights are equal to 1
criterion torch.nn.bcewithlogitsloss pos weight pos weight
criterion output, target # log sigmoid 0999
tensor 03135
examples

loss nn.bcewithlogitsloss
input torch.randn 3, requires grad true
target torch.empty 3 .random 2
output loss input, target
output.backward","args
weight tensor, optional a manual rescaling weight given to the loss
of each batch element. if given, has to be a tensor of size nbatch .
size average bool, optional deprecated see attr reduction . by default,
the losses are averaged over each loss element in the batch. note that for
some losses, there are multiple elements per sample. if the field attr size average
is set to false , the losses are instead summed for each minibatch. ignored
when reduce is false . default true
reduce bool, optional deprecated see attr reduction . by default, the
losses are averaged or summed over observations for each minibatch depending
on attr size average . when attr reduce is false , returns a loss per
batch element instead and ignores attr size average . default true
reduction string, optional specifies the reduction to apply to the output
none mean sum . none no reduction will be applied,
mean the sum of the output will be divided by the number of
elements in the output, sum the output will be summed. note attr size average
and attr reduce are in the process of being deprecated, and in the meantime,
specifying either of those two args will override attr reduction . default mean
pos weight tensor, optional a weight of positive examples.
must be a vector with length equal to the number of classes.

shape
input math n, where math means, any number of additional dimensions
target math n, , same shape as the input
output scalar. if attr reduction is none , then math n, , same
shape as input.","the unreduced ie with attr reduction set to none loss can be described as

math
ell x, y l l 1, dots,l n ^ top, quad
l n w n left y n cdot log sigma x n
1 y n cdot log 1 sigma x n right ,

where math n is the batch size. if attr reduction is not none
default mean , then

math
ell x, y begin cases
operatorname mean l , & text if reduction text mean
operatorname sum l , & text if reduction text sum .
end cases

this is used for measuring the error of a reconstruction in for example
an auto encoder. note that the targets t i should be numbers
between 0 and 1.

it s possible to trade off recall and precision by adding weights to positive examples.
in the case of multi label classification the loss can be described as

math
ell c x, y l c l 1,c , dots,l n,c ^ top, quad
l n,c w n,c left p c y n,c cdot log sigma x n,c
1 y n,c cdot log 1 sigma x n,c right ,

where math c is the class number math c 1 for multi label binary classification,
math c 1 for single label binary classification ,
math n is the number of the sample in the batch and
math p c is the weight of the positive answer for the class math c .

math p c 1 increases the recall, math p c 1 increases the precision.","note that the targets t i should be numbers
between 0 and 1."
6,BoundedGradientProjection,"wright, s., & nocedal, j. 1999 . numerical optimization. springer science,
35 67 68 , 7. chapter 16",,,,,
6,BuildType,"checks build type. the build type will be given in attr cmake build type env . if attr cmake build type env
is none , then the build type will be inferred from cmakecache.txt . if cmakecache.txt does not exist,
os.environ cmake build type will be used.

arguments
cmake build type env str the value of os.environ cmake build type . if none, the actual build type will be
inferred.",checks build type.,"the build type will be given in attr cmake build type env . if attr cmake build type env
is none , then the build type will be inferred from cmakecache.txt . if cmakecache.txt does not exist,
os.environ cmake build type will be used.","arguments
cmake build type env str the value of os.environ cmake build type . if none, the actual build type will be inferred.",,
6,Caffe2OperatorTestCase,"this class includes all the information needed to benchmark an operator.
op bench it s a user defined class child of caffe2benchmarkbase
which includes input and operator, .etc
test config a namedtuple includes test name, input shape, tag, run backward.
when run backward is false, the run forward method will be executed, otherwise
run backward method will be executed.",this class includes all the information needed to benchmark an operator.,,,"op bench it s a user defined class child of caffe2benchmarkbase
which includes input and operator, .etc
test config a namedtuple includes test name, input shape, tag, run backward.
when run backward is false, the run forward method will be executed, otherwise
run backward method will be executed.",
6,ConstantPad3d,"pads the input tensor boundaries with a constant value.

for n dimensional padding, use func torch.nn.functional.pad .

args
padding int, tuple the size of the padding. if is int , uses the same
padding in all boundaries. if a 6 tuple , uses
math text padding left , math text padding right ,
math text padding top , math text padding bottom ,
math text padding front , math text padding back

shape
input math n, c, d in , h in , w in
output math n, c, d out , h out , w out where

math d out d in text padding front text padding back

math h out h in text padding top text padding bottom

math w out w in text padding left text padding right

examples

m nn.constantpad3d 3, 35
input torch.randn 16, 3, 10, 20, 30
output m input
# using different paddings for different sides
m nn.constantpad3d 3, 3, 6, 6, 0, 1 , 35
output m input",pads the input tensor boundaries with a constant value.,"for n dimensional padding, use func torch.nn.functional.pad .

examples

m nn.constantpad3d 3, 35
input torch.randn 16, 3, 10, 20, 30
output m input
# using different paddings for different sides
m nn.constantpad3d 3, 3, 6, 6, 0, 1 , 35
output m input","args
padding int, tuple the size of the padding. if is int , uses the same
padding in all boundaries. if a 6 tuple , uses
math text padding left , math text padding right ,
math text padding top , math text padding bottom ,
math text padding front , math text padding back",,
6,Conv3d,"applies a 3d convolution over an input signal composed of several input
planes.

in the simplest case, the output value of the layer with input size math n, c in , d, h, w
and output math n, c out , d out , h out , w out can be precisely described as

math
out n i, c out j bias c out j
sum k 0 ^ c in 1 weight c out j , k star input n i, k

where math star is the valid 3d cross correlation operator

attr stride controls the stride for the cross correlation.

attr padding controls the amount of implicit zero paddings on both
sides for attr padding number of points for each dimension.

attr dilation controls the spacing between the kernel points also known as the trous algorithm.
it is harder to describe, but this link has a nice visualization of what attr dilation does.

attr groups controls the connections between inputs and outputs.
attr in channels and attr out channels must both be divisible by
attr groups . for example,

at groups 1, all inputs are convolved to all outputs.
at groups 2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.
at groups attr in channels , each input channel is convolved with
its own set of filters, of size
math left lfloor frac out channels in channels right rfloor .

the parameters attr kernel size , attr stride , attr padding , attr dilation can either be

a single int in which case the same value is used for the depth, height and width dimension
a tuple of three ints in which case, the first int is used for the depth dimension,
the second int for the height dimension and the third int for the width dimension

note

depending of the size of your kernel, several of the last
columns of the input might be lost, because it is a valid cross correlation ,
and not a full cross correlation .
it is up to the user to add proper padding.

note

when groups in channels and out channels k in channels ,
where k is a positive integer, this operation is also termed in
literature as depthwise convolution.

in other words, for an input of size math n, c in , d in , h in , w in ,
a depthwise convolution with a depthwise multiplier k , can be constructed by arguments
math in channels c in , out channels c in times k, ..., groups c in .

include cudnn deterministic.rst

args
in channels int number of channels in the input image
out channels int number of channels produced by the convolution
kernel size int or tuple size of the convolving kernel
stride int or tuple, optional stride of the convolution. default 1
padding int or tuple, optional zero padding added to all three sides of the input. default 0
padding mode string, optional . accepted values zeros and circular default zeros
dilation int or tuple, optional spacing between kernel elements. default 1
groups int, optional number of blocked connections from input channels to output channels. default 1
bias bool, optional if true , adds a learnable bias to the output. default true

shape
input math n, c in , d in , h in , w in
output math n, c out , d out , h out , w out where

math
d out left lfloor frac d in 2 times text padding 0 text dilation 0
times text kernel size 0 1 1 text stride 0 1 right rfloor

math
h out left lfloor frac h in 2 times text padding 1 text dilation 1
times text kernel size 1 1 1 text stride 1 1 right rfloor

math
w out left lfloor frac w in 2 times text padding 2 text dilation 2
times text kernel size 2 1 1 text stride 2 1 right rfloor

attributes
weight tensor the learnable weights of the module of shape
math text out channels , frac text in channels text groups ,
math text kernel size 0 , text kernel size 1 , text kernel size 2 .
the values of these weights are sampled from
math mathcal u sqrt k , sqrt k where
math k frac 1 c text in prod i 0 ^ 2 text kernel size i
bias tensor the learnable bias of the module of shape out channels . if attr bias is true ,
then the values of these weights are
sampled from math mathcal u sqrt k , sqrt k where
math k frac 1 c text in prod i 0 ^ 2 text kernel size i

examples

# with square kernels and equal stride
m nn.conv3d 16, 33, 3, stride 2
# non square kernels and unequal stride and with padding
m nn.conv3d 16, 33, 3, 5, 2 , stride 2, 1, 1 , padding 4, 2, 0
input torch.randn 20, 16, 10, 50, 100
output m input

cross correlation
https en.wikipedia.org wiki cross correlation

link
https github.com vdumoulin conv arithmetic blob master readme.md","applies a 3d convolution over an input signal composed of several input
planes.
at groups 1, all inputs are convolved to all outputs.
at groups 2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.
at groups attr in channels , each input channel is convolved with
its own set of filters, of size
math left lfloor frac out channels in channels right rfloor .

the parameters attr kernel size , attr stride , attr padding , attr dilation can either be

a single int in which case the same value is used for the depth, height and width dimension
a tuple of three ints in which case, the first int is used for the depth dimension,
the second int for the height dimension and the third int for the width dimension","examples

# with square kernels and equal stride
m nn.conv3d 16, 33, 3, stride 2
# non square kernels and unequal stride and with padding
m nn.conv3d 16, 33, 3, 5, 2 , stride 2, 1, 1 , padding 4, 2, 0
input torch.randn 20, 16, 10, 50, 100
output m input","the parameters attr kernel size , attr stride , attr padding , attr dilation can either be

a single int in which case the same value is used for the depth, height and width dimension
a tuple of three ints in which case, the first int is used for the depth dimension,
the second int for the height dimension and the third int for the width dimension

attr stride controls the stride for the cross correlation.

attr padding controls the amount of implicit zero paddings on both
sides for attr padding number of points for each dimension.

attr dilation controls the spacing between the kernel points also known as the trous algorithm.
it is harder to describe, but this link has a nice visualization of what attr dilation does.

attr groups controls the connections between inputs and outputs.
attr in channels and attr out channels must both be divisible by
attr groups .

args
in channels int number of channels in the input image
out channels int number of channels produced by the convolution
kernel size int or tuple size of the convolving kernel
stride int or tuple, optional stride of the convolution. default 1
padding int or tuple, optional zero padding added to all three sides of the input. default 0
padding mode string, optional . accepted values zeros and circular default zeros
dilation int or tuple, optional spacing between kernel elements. default 1
groups int, optional number of blocked connections from input channels to output channels. default 1
bias bool, optional if true , adds a learnable bias to the output. default true","n the simplest case, the output value of the layer with input size math n, c in , d, h, w
and output math n, c out , d out , h out , w out can be precisely described as

math
out n i, c out j bias c out j
sum k 0 ^ c in 1 weight c out j , k star input n i, k

where math star is the valid 3d cross correlation operator

attributes
weight tensor the learnable weights of the module of shape
math text out channels , frac text in channels text groups ,
math text kernel size 0 , text kernel size 1 , text kernel size 2 .
the values of these weights are sampled from
math mathcal u sqrt k , sqrt k where
math k frac 1 c text in prod i 0 ^ 2 text kernel size i
bias tensor the learnable bias of the module of shape out channels . if attr bias is true ,
then the values of these weights are
sampled from math mathcal u sqrt k , sqrt k where
math k frac 1 c text in prod i 0 ^ 2 text kernel size i",
6,ConvReLU3d,"a convrelu3d module is a fused module of conv3d and relu

we adopt the same interface as class torch.nn.quantized.conv3d .

note
attributes same as torch.nn.quantized.conv3d",a convrelu3d module is a fused module of conv3d and relu,,,"we adopt the same interface as class torch.nn.quantized.conv3d .
attributes same as torch.nn.quantized.conv3d","note
attributes same as torch.nn.quantized.conv3d"
6,cuFFTPlanCacheAttrContextProp,"like regular contextprop, but uses the .device index attribute from the
calling object as the first argument to the getter and setter.","like regular contextprop, but uses the .device index attribute from the calling object as the first argument to the getter and setter.",,"like regular contextprop, but uses the .device index attribute from the calling object as the first argument to the getter and setter.",,
6,CyclicLR,"sets the learning rate of each parameter group according to
cyclical learning rate policy clr . the policy cycles the learning
rate between two boundaries with a constant frequency, as detailed in
the paper cyclical learning rates for training neural networks .
the distance between the two boundaries can be scaled on a per iteration
or per cycle basis.

cyclical learning rate policy changes the learning rate after every batch.
step should be called after a batch has been used for training.

this class has three built in policies, as put forth in the paper

triangular a basic triangular cycle without amplitude scaling.
triangular2 a basic triangular cycle that scales initial amplitude by half each cycle.
exp range a cycle that scales initial amplitude by math text gamma ^ text cycle iterations
at each cycle iteration.

this implementation was adapted from the github repo bckenstler clr

args
optimizer optimizer wrapped optimizer.
base lr float or list initial learning rate which is the
lower boundary in the cycle for each parameter group.
max lr float or list upper learning rate boundaries in the cycle
for each parameter group. functionally,
it defines the cycle amplitude max lr base lr .
the lr at any cycle is the sum of base lr
and some scaling of the amplitude therefore
max lr may not actually be reached depending on
scaling function.
step size up int number of training iterations in the
increasing half of a cycle. default 2000
step size down int number of training iterations in the
decreasing half of a cycle. if step size down is none,
it is set to step size up. default none
mode str one of triangular, triangular2, exp range .
values correspond to policies detailed above.
if scale fn is not none, this argument is ignored.
default triangular
gamma float constant in exp range scaling function
gamma cycle iterations
default 10
scale fn function custom scaling policy defined by a single
argument lambda function, where
0 scale fn x 1 for all x 0.
if specified, then mode is ignored.
default none
scale mode str cycle , iterations .
defines whether scale fn is evaluated on
cycle number or cycle iterations training
iterations since start of cycle .
default cycle
cycle momentum bool if true , momentum is cycled inversely
to learning rate between base momentum and max momentum .
default true
base momentum float or list lower momentum boundaries in the cycle
for each parameter group. note that momentum is cycled inversely
to learning rate at the peak of a cycle, momentum is
base momentum and learning rate is max lr .
default 08
max momentum float or list upper momentum boundaries in the cycle
for each parameter group. functionally,
it defines the cycle amplitude max momentum base momentum .
the momentum at any cycle is the difference of max momentum
and some scaling of the amplitude therefore
base momentum may not actually be reached depending on
scaling function. note that momentum is cycled inversely
to learning rate at the start of a cycle, momentum is max momentum
and learning rate is base lr
default 09
last epoch int the index of the last batch. this parameter is used when
resuming a training job. since step should be invoked after each
batch instead of after each epoch, this number represents the total
number of batches computed, not the total number of epochs computed.
when last epoch 1, the schedule is started from the beginning.
default 1

example
optimizer torch.optim.sgd model.parameters , lr 01, momentum 09
scheduler torch.optim.lr scheduler.cycliclr optimizer, base lr 001, max lr 01
data loader torch.utils.data.dataloader ...
for epoch in range 10
for batch in data loader
train batch ...
scheduler.step

cyclical learning rates for training neural networks https arxiv.org abs 150601186
bckenstler clr https github.com bckenstler clr","sets the learning rate of each parameter group according to
cyclical learning rate policy clr . the policy cycles the learning
rate between two boundaries with a constant frequency, as detailed in
the paper cyclical learning rates for training neural networks .
the distance between the two boundaries can be scaled on a per iteration
or per cycle basis.","in the simplest case, the output value of the layer with input size math n, c in , d, h, w
and output math n, c out , d out , h out , w out can be precisely described as

math
out n i, c out j bias c out j
sum k 0 ^ c in 1 weight c out j , k star input n i, k

where math star is the valid 3d cross correlation operator

example
optimizer torch.optim.sgd model.parameters , lr 01, momentum 09
scheduler torch.optim.lr scheduler.cycliclr optimizer, base lr 001, max lr 01
data loader torch.utils.data.dataloader ...
for epoch in range 10
for batch in data loader
train batch ...
scheduler.step","triangular a basic triangular cycle without amplitude scaling.
triangular2 a basic triangular cycle that scales initial amplitude by half each cycle.
exp range a cycle that scales initial amplitude by math text gamma ^ text cycle iterations
at each cycle iteration.","cyclical learning rate policy changes the learning rate after every batch.
step should be called after a batch has been used for training.this class has three built in policies, as put forth in the paper

triangular a basic triangular cycle without amplitude scaling.
triangular2 a basic triangular cycle that scales initial amplitude by half each cycle.
exp range a cycle that scales initial amplitude by math text gamma ^ text cycle iterations
at each cycle iteration.",
6,DeQuantStub,"dequantize stub module, before calibration, this is same as identity,
this will be swapped as nnq.dequantize in convert .","dequantize stub module, before calibration, this is same as identity,
this will be swapped as nnq.dequantize in convert .",,,"this is same as identity,
this will be swapped as nnq.dequantize in convert .",
6,DiagonalTensor,"a class with torch function and a specific diagonal representation

this class has limited utility and is mostly useful for verifying that the
dispatch mechanism works as expected. it is based on the diagonalarray
example in the numpy documentation.

note that this class does not inherit from torch.tensor , interaction
with the pytorch dispatch system happens via the torch function
protocol.

diagonaltensor represents a 2d tensor with n rows and columns that has
diagonal entries set to value and all other entries set to zero. the
main functionality of diagonaltensor is to provide a more compact
string representation of a diagonal tensor than in the base tensor class

d diagonaltensor 5, 2
d
diagonaltensor n 5, value 2
d.tensor
tensor 2., 0., 0., 0., 0. ,
0., 2., 0., 0., 0. ,
0., 0., 2., 0., 0. ,
0., 0., 0., 2., 0. ,
0., 0., 0., 0., 2.

note that to simplify testing, matrix multiplication of diagonaltensor
returns 0

torch.mm d, d
0

diagonalarray example
https numpy.org devdocs user basics.dispatch.html",a class with torch function and a specific diagonal representation,"this class has limited utility and is mostly useful for verifying that the
dispatch mechanism works as expected. it is based on the diagonalarray
example in the numpy documentation.",,"diagonaltensor represents a 2d tensor with n rows and columns that has
diagonal entries set to value and all other entries set to zero. the
main functionality of diagonaltensor is to provide a more compact
string representation of a diagonal tensor than in the base tensor class",
6,EmbeddingBag,"computes sums or means of bags of embeddings, without instantiating the
intermediate embeddings.

for bags of constant length and no attr per sample weights , this class

with mode sum is equivalent to class torch.nn.embedding followed by torch.sum dim 0 ,
with mode mean is equivalent to class torch.nn.embedding followed by torch.mean dim 0 ,
with mode max is equivalent to class torch.nn.embedding followed by torch.max dim 0 .

however, class torch.nn.embeddingbag is much more time and memory efficient than using a chain of these
operations.

embeddingbag also supports per sample weights as an argument to the forward
pass. this scales the output of the embedding before performing a weighted
reduction as specified by mode . if attr per sample weights is passed, the
only supported mode is sum , which computes a weighted sum according to
attr per sample weights .

args
num embeddings int size of the dictionary of embeddings
embedding dim int the size of each embedding vector
max norm float, optional if given, each embedding vector with norm larger than attr max norm
is renormalized to have norm attr max norm .
norm type float, optional the p of the p norm to compute for the attr max norm option. default 2 .
scale grad by freq boolean, optional if given, this will scale gradients by the inverse of frequency of
the words in the mini batch. default false .
note this option is not supported when mode max .
mode string, optional sum , mean or max . specifies the way to reduce the bag.
sum computes the weighted sum, taking attr per sample weights
into consideration. mean computes the average of the values
in the bag, max computes the max value over each bag.
default mean
sparse bool, optional if true , gradient w.r.t. attr weight matrix will be a sparse tensor. see
notes for more details regarding sparse gradients. note this option is not
supported when mode max .

attributes
weight tensor the learnable weights of the module of shape num embeddings, embedding dim
initialized from math mathcal n 0, 1 .

inputs attr input longtensor , attr offsets longtensor, optional , and
attr per index weights tensor, optional

if attr input is 2d of shape b, n ,

it will be treated as b bags sequences each of fixed length n , and
this will return b values aggregated in a way depending on the attr mode .
attr offsets is ignored and required to be none in this case.

if attr input is 1d of shape n ,

it will be treated as a concatenation of multiple bags sequences .
attr offsets is required to be a 1d tensor containing the
starting index positions of each bag in attr input . therefore,
for attr offsets of shape b , attr input will be viewed as
having b bags. empty bags ie, having 0 length will have
returned vectors filled by zeros.

per sample weights tensor, optional a tensor of float double weights, or none
to indicate all weights should be taken to be 1 . if specified, attr per sample weights
must have exactly the same shape as input and is treated as having the same
attr offsets , if those are not none . only supported for mode sum .

output shape b, embedding dim

examples

# an embedding module containing 10 tensors of size 3
embedding sum nn.embeddingbag 10, 3, mode sum
# a batch of 2 samples of 4 indices each
input torch.longtensor 1,2,4,5,4,3,2,9
offsets torch.longtensor 0,4
embedding sum input, offsets
tensor 08861, 54350, 00523 ,
11306, 25798, 10044","computes sums or means of bags of embeddings, without instantiating the
intermediate embeddings.","examples

# an embedding module containing 10 tensors of size 3
embedding sum nn.embeddingbag 10, 3, mode sum
# a batch of 2 samples of 4 indices each
input torch.longtensor 1,2,4,5,4,3,2,9
offsets torch.longtensor 0,4
embedding sum input, offsets
tensor 08861, 54350, 00523 ,
11306, 25798, 10044","args
num embeddings int size of the dictionary of embeddings
embedding dim int the size of each embedding vector
max norm float, optional if given, each embedding vector with norm larger than attr max norm
is renormalized to have norm attr max norm .
norm type float, optional the p of the p norm to compute for the attr max norm option. default 2 .
scale grad by freq boolean, optional if given, this will scale gradients by the inverse of frequency of
the words in the mini batch. default false .
note this option is not supported when mode max .
mode string, optional sum , mean or max . specifies the way to reduce the bag.
sum computes the weighted sum, taking attr per sample weights
into consideration. mean computes the average of the values
in the bag, max computes the max value over each bag.
default mean
sparse bool, optional if true , gradient w.r.t. attr weight matrix will be a sparse tensor. see
notes for more details regarding sparse gradients. note this option is not
supported when mode max .","attributes
weight tensor the learnable weights of the module of shape num embeddings, embedding dim
initialized from math mathcal n 0, 1 .

inputs attr input longtensor , attr offsets longtensor, optional , and
attr per index weights tensor, optional

if attr input is 2d of shape b, n ,

it will be treated as b bags sequences each of fixed length n , and
this will return b values aggregated in a way depending on the attr mode .
attr offsets is ignored and required to be none in this case.

if attr input is 1d of shape n ,

it will be treated as a concatenation of multiple bags sequences .
attr offsets is required to be a 1d tensor containing the
starting index positions of each bag in attr input . therefore,
for attr offsets of shape b , attr input will be viewed as
having b bags. empty bags ie, having 0 length will have
returned vectors filled by zeros.

per sample weights tensor, optional a tensor of float double weights, or none
to indicate all weights should be taken to be 1 . if specified, attr per sample weights
must have exactly the same shape as input and is treated as having the same
attr offsets , if those are not none . only supported for mode sum .","for bags of constant length and no attr per sample weights , this class

with mode sum is equivalent to class torch.nn.embedding followed by torch.sum dim 0 ,
with mode mean is equivalent to class torch.nn.embedding followed by torch.mean dim 0 ,
with mode max is equivalent to class torch.nn.embedding followed by torch.max dim 0 .

however, class torch.nn.embeddingbag is much more time and memory efficient than using a chain of these
operations.

embeddingbag also supports per sample weights as an argument to the forward
pass. this scales the output of the embedding before performing a weighted
reduction as specified by mode . if attr per sample weights is passed, the
only supported mode is sum , which computes a weighted sum according to
attr per sample weights ."
6,EnforceUnique,raises an error if a key is seen more than once.,raises an error if a key is seen more than once.,,,,
6,Error,"each error is a section in the output of cuda memcheck.
each error in the report has an error message and a backtrace. it looks like

program hit cudaerrorinvalidvalue error 1 due to invalid argument on cuda api call to cudagetlasterror.
saved host backtrace up to driver entry point at error
host frame usr lib x86 64 linux gnu libcuda.so.1 0x38c7b3
host frame usr local cuda lib64 libcudart.so.101 cudagetlasterror 0x163 0x4c493
host frame home xgao anaconda3 lib python37 site packages torch lib libtorch.so 0x5b77a05
host frame home xgao anaconda3 lib python37 site packages torch lib libtorch.so 0x39d6d1d",each error is a section in the output of cuda memcheck.,,,each error in the report has an error message and a backtrace,
6,ExceptionWrapper,wraps an exception plus traceback to communicate across threads,wraps an exception plus traceback to communicate across threads,,,,
6,ExternalInitializer,"this class is used in cases when the parameter should not be initialized by
the initializer, but rather provided in the workspace when param init net is
executed.

current version is not doing any real sanity checks to the parameter.",,"this class is used in cases when the parameter should not be initialized by
the initializer, but rather provided in the workspace when param init net is
executed.",,,current version is not doing any real sanity checks to the parameter.
6,FisherSnedecor,"creates a fisher snedecor distribution parameterized by attr df1 and attr df2 .

example

m fishersnedecor torch.tensor 10 , torch.tensor 20
m.sample # fisher snedecor distributed with df1 1 and df2 2
tensor 02453

args
df1 float or tensor degrees of freedom parameter 1
df2 float or tensor degrees of freedom parameter 2",creates a fisher snedecor distribution parameterized by attr df1 and attr df2 .,"example

m fishersnedecor torch.tensor 10 , torch.tensor 20
m.sample # fisher snedecor distributed with df1 1 and df2 2
tensor 02453","args
df1 float or tensor degrees of freedom parameter 1
df2 float or tensor degrees of freedom parameter 2",,
6,LastNWindowCollector,"collect last n samples from input record. if you have complex data,
use packrecords to pack it before using this layer.

this layer is not thread safe.",collect last n samples from input record.,,,,"if you have complex data,
use packrecords to pack it before using this layer.

this layer is not thread safe."
6,LBFGS,"implements l bfgs algorithm, heavily inspired by minfunc
https www.cs.ubc.ca schmidtm software minfunc.html .

warning
this optimizer doesn t support per parameter options and parameter
groups there can be only one .

warning
right now all parameters have to be on a single device. this will be
improved in the future.

note
this is a very memory intensive optimizer it requires additional
param bytes history size 1 bytes . if it doesn t fit in memory
try reducing the history size, or use a different algorithm.

arguments
lr float learning rate default 1
max iter int maximal number of iterations per optimization step
default 20
max eval int maximal number of function evaluations per optimization
step default max iter 125 .
tolerance grad float termination tolerance on first order optimality
default 1e 5 .
tolerance change float termination tolerance on function
value parameter changes default 1e 9 .
history size int update history size default 100 .
line search fn str either strong wolfe or none default none .","implements l bfgs algorithm, heavily inspired by minfunc",,"arguments
lr float learning rate default 1
max iter int maximal number of iterations per optimization step
default 20
max eval int maximal number of function evaluations per optimization
step default max iter 125 .
tolerance grad float termination tolerance on first order optimality
default 1e 5 .
tolerance change float termination tolerance on function
value parameter changes default 1e 9 .
history size int update history size default 100 .
line search fn str either strong wolfe or none default none .",,"note
this is a very memory intensive optimizer it requires additional
param bytes history size 1 bytes . if it doesn t fit in memory
try reducing the history size, or use a different algorithm."
6,Module,"base class for all neural network modules.

your models should also subclass this class.

modules can also contain other modules, allowing to nest them in
a tree structure. you can assign the submodules as regular attributes

import torch.nn as nn
import torch.nn.functional as f

class model nn.module
def init self
super model, self . init
self.conv1 nn.conv2d 1, 20, 5
self.conv2 nn.conv2d 20, 20, 5

def forward self, x
x f.relu self.conv1 x
return f.relu self.conv2 x

submodules assigned in this way will be registered, and will have their
parameters converted too when you call meth to , etc",base class for all neural network modules.,"import torch.nn as nn
import torch.nn.functional as f

class model nn.module
def init self
super model, self . init
self.conv1 nn.conv2d 1, 20, 5
self.conv2 nn.conv2d 20, 20, 5

def forward self, x
x f.relu self.conv1 x
return f.relu self.conv2 x",,"modules can also contain other modules, allowing to nest them in
a tree structure. you can assign the submodules as regular attributes

submodules assigned in this way will be registered, and will have their
parameters converted too when you call meth to , etc",
6,MultiLabelMarginLoss,"creates a criterion that optimizes a multi class multi classification
hinge loss margin based loss between input math x a 2d mini batch tensor
and output math y which is a 2d tensor of target class indices .
for each sample in the mini batch

math
text loss x, y sum ij frac max 0, 1 x y j x i text x.size 0

where math x in left 0, cdots , text x.size 0 1 right ,
math y in left 0, cdots , text y.size 0 1 right ,
math 0 leq y j leq text x.size 0 1 ,
and math i neq y j for all math i and math j .

math y and math x must have the same size.

the criterion only considers a contiguous block of non negative targets that
starts at the front.

this allows for different samples to have variable amounts of target classes.

args
size average bool, optional deprecated see attr reduction . by default,
the losses are averaged over each loss element in the batch. note that for
some losses, there are multiple elements per sample. if the field attr size average
is set to false , the losses are instead summed for each minibatch. ignored
when reduce is false . default true
reduce bool, optional deprecated see attr reduction . by default, the
losses are averaged or summed over observations for each minibatch depending
on attr size average . when attr reduce is false , returns a loss per
batch element instead and ignores attr size average . default true
reduction string, optional specifies the reduction to apply to the output
none mean sum . none no reduction will be applied,
mean the sum of the output will be divided by the number of
elements in the output, sum the output will be summed. note attr size average
and attr reduce are in the process of being deprecated, and in the meantime,
specifying either of those two args will override attr reduction . default mean

shape
input math c or math n, c where n is the batch size and c
is the number of classes.
target math c or math n, c , label targets padded by 1 ensuring same shape as the input.
output scalar. if attr reduction is none , then math n .

examples

loss nn.multilabelmarginloss
x torch.floattensor 01, 02, 04, 08
# for target y, only consider labels 3 and 0, not after label 1
y torch.longtensor 3, 0, 1, 1
loss x, y
# 025 1 01 02 1 01 04 1 08 02 1 08 04
tensor 08500","creates a criterion that optimizes a multi class multi classification
hinge loss margin based loss between input math x a 2d mini batch tensor
and output math y which is a 2d tensor of target class indices .","examples

loss nn.multilabelmarginloss
x torch.floattensor 01, 02, 04, 08
# for target y, only consider labels 3 and 0, not after label 1
y torch.longtensor 3, 0, 1, 1
loss x, y
# 025 1 01 02 1 01 04 1 08 02 1 08 04
tensor 08500","args
size average bool, optional deprecated see attr reduction . by default,
the losses are averaged over each loss element in the batch. note that for
some losses, there are multiple elements per sample. if the field attr size average
is set to false , the losses are instead summed for each minibatch. ignored
when reduce is false . default true
reduce bool, optional deprecated see attr reduction . by default, the
losses are averaged or summed over observations for each minibatch depending
on attr size average . when attr reduce is false , returns a loss per
batch element instead and ignores attr size average . default true
reduction string, optional specifies the reduction to apply to the output
none mean sum . none no reduction will be applied,
mean the sum of the output will be divided by the number of
elements in the output, sum the output will be summed. note attr size average
and attr reduce are in the process of being deprecated, and in the meantime,
specifying either of those two args will override attr reduction . default mean","for each sample in the mini batch

math
text loss x, y sum ij frac max 0, 1 x y j x i text x.size 0

where math x in left 0, cdots , text x.size 0 1 right ,
math y in left 0, cdots , text y.size 0 1 right ,
math 0 leq y j leq text x.size 0 1 ,
and math i neq y j for all math i and math j .

math y and math x must have the same size.
the criterion only considers a contiguous block of non negative targets that
starts at the front.

this allows for different samples to have variable amounts of target classes.",
6,NetModifier,"an abstraction class for supporting modifying a generated net.
inherited classes should implement the modify net method where
related operators are added to the net.

example usage
modifier somenetmodifier opts
modifier net",an abstraction class for supporting modifying a generated net.,"example usage
modifier somenetmodifier opts
modifier net",,"inherited classes should implement the modify net method where
related operators are added to the net.",
6,OneHotCategorical,"creates a one hot categorical distribution parameterized by attr probs or
attr logits .

samples are one hot coded vectors of size probs.size 1 .

note attr probs must be non negative, finite and have a non zero sum,
and it will be normalized to sum to 1.

see also func torch.distributions.categorical for specifications of
attr probs and attr logits .

example

m onehotcategorical torch.tensor 025, 025, 025, 025
m.sample # equal probability of 0, 1, 2, 3
tensor 0., 0., 0., 1.

args
probs tensor event probabilities
logits tensor event log probabilities","creates a one hot categorical distribution parameterized by attr probs or
attr logits .","example

m onehotcategorical torch.tensor 025, 025, 025, 025
m.sample # equal probability of 0, 1, 2, 3
tensor 0., 0., 0., 1.","args
probs tensor event probabilities
logits tensor event log probabilities",samples are one hot coded vectors of size probs.size 1 .,"note attr probs must be non negative, finite and have a non zero sum,
and it will be normalized to sum to 1."
6,Poisson,"creates a poisson distribution parameterized by attr rate , the rate parameter.

samples are nonnegative integers, with a pmf given by

math
mathrm rate ^k frac e^ mathrm rate k!

example

m poisson torch.tensor 4
m.sample
tensor 3.

args
rate number, tensor the rate parameter","creates a poisson distribution parameterized by attr rate , the rate parameter.","samples are nonnegative integers, with a pmf given by

math
mathrm rate ^k frac e^ mathrm rate k!

example

m poisson torch.tensor 4
m.sample
tensor 3.","args
rate number, tensor the rate parameter","samples are nonnegative integers, with a pmf given by

math
mathrm rate ^k frac e^ mathrm rate k!",
6,QuantWrapper,"a wrapper class that wraps the input module, adds quantstub and
dequantstub and surround the call to module with call to quant and dequant
modules.

this is used by the quantization utility functions to add the quant and
dequant modules, before convert function quantstub will just be observer,
it observes the input tensor, after convert , quantstub
will be swapped to nnq.quantize which does actual quantization. similarly
for dequantstub .","a wrapper class that wraps the input module, adds quantstub and
dequantstub and surround the call to module with call to quant and dequant
modules.",,,"this is used by the quantization utility functions to add the quant and
dequant modules, before convert function quantstub will just be observer,
it observes the input tensor, after convert , quantstub
will be swapped to nnq.quantize which does actual quantization. similarly
for dequantstub .",
6,ResNetBuilder,helper class for constructing residual blocks.,helper class for constructing residual blocks.,,,,
6,SGD,"implements stochastic gradient descent optionally with momentum .

nesterov momentum is based on the formula from
on the importance of initialization and momentum in deep learning .

args
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float learning rate
momentum float, optional momentum factor default 0
weight decay float, optional weight decay l2 penalty default 0
dampening float, optional dampening for momentum default 0
nesterov bool, optional enables nesterov momentum default false

example
optimizer torch.optim.sgd model.parameters , lr 01, momentum 09
optimizer.zero grad
loss fn model input , target .backward
optimizer.step

http www.cs.toronto.edu %7ehinton absps momentum.pdf

note
the implementation of sgd with momentum nesterov subtly differs from
sutskever et. al. and implementations in some other frameworks.

considering the specific case of momentum, the update can be written as

math
v t 1 mu v t g t 1
p t 1 p t lr v t 1

where p, g, v and math mu denote the parameters, gradient,
velocity, and momentum respectively.

this is in contrast to sutskever et. al. and
other frameworks which employ an update of the form

math
v t 1 mu v t lr g t 1
p t 1 p t v t 1

the nesterov version is analogously modified.",implements stochastic gradient descent optionally with momentum .,"example
optimizer torch.optim.sgd model.parameters , lr 01, momentum 09
optimizer.zero grad
loss fn model input , target .backward
optimizer.step","args
params iterable iterable of parameters to optimize or dicts defining
parameter groups
lr float learning rate
momentum float, optional momentum factor default 0
weight decay float, optional weight decay l2 penalty default 0
dampening float, optional dampening for momentum default 0
nesterov bool, optional enables nesterov momentum default false","nesterov momentum is based on the formula from
on the importance of initialization and momentum in deep learning .","nesterov momentum is based on the formula from
on the importance of initialization and momentum in deep learning ."
6,SharedCache,dictionary from multiprocessing handles to storageweakref,dictionary from multiprocessing handles to storageweakref,,,,
6,StackedLSTMWithDropout,necessary for iterating through self.layers and dropout support,necessary for iterating through self.layers and dropout support,,,,
6,StackTransform,"transform functor that applies a sequence of transforms tseq
component wise to each submatrix at dim
in a way compatible with func torch.stack .

example
x torch.stack torch.range 1, 10 , torch.range 1, 10 , dim 1
t stacktransform exptransform , identity transform , dim 1
y t x","transform functor that applies a sequence of transforms tseq
component wise to each submatrix at dim
in a way compatible with func torch.stack .","example
x torch.stack torch.range 1, 10 , torch.range 1, 10 , dim 1
t stacktransform exptransform , identity transform , dim 1
y t x",,,
6,Subset,"subset of a dataset at specified indices.

arguments
dataset dataset the whole dataset
indices sequence indices in the whole set selected for subset",subset of a dataset at specified indices,,"arguments
dataset dataset the whole dataset
indices sequence indices in the whole set selected for subset",,
6,Task,"a task is composed of an execution step and zero or more outputs.
tasks are executed in the context of a taskgroup, which, in turn, can
be run by a session.

task outputs are fetched by the session at the end of the run.

the recommended way of creating a task is by using net builder.ops .
example

from net builder import ops
with node trainer , task name my task , num instances 2
with ops.task init
globl ops.const 0
with ops.task instance init
local ops.const 0
with ops.loop 100
ops.copy globl, local
with ops.task instance exit
ops.add globl, local , globl
with ops.task exit
ops.mul globl, globl , globl

the task above will create 2 instances that will run in parallel.
each instance will copy local to globl 100 times, then add local
to globl once. the mul will only execute once, after all the instances
of the task have finished.",a task is composed of an execution step and zero or more outputs.,"example

from net builder import ops
with node trainer , task name my task , num instances 2
with ops.task init
globl ops.const 0
with ops.task instance init
local ops.const 0
with ops.loop 100
ops.copy globl, local
with ops.task instance exit
ops.add globl, local , globl
with ops.task exit
ops.mul globl, globl , globl

the task above will create 2 instances that will run in parallel.
each instance will copy local to globl 100 times, then add local
to globl once. the mul will only execute once, after all the instances
of the task have finished.",,"tasks are executed in the context of a taskgroup, which, in turn, can
be run by a session.

task outputs are fetched by the session at the end of the run.",
6,TaskOutput,"represents the output of a task. an output can be a blob,
a list of blob, or a record.",represents the output of a task.,,"an output can be a blob, a list of blob, or a record.",,
6,TestBuiltins,tests for torchscript support of python builtin functions.,tests for torchscript support of python builtin functions.,,,,
6,TestQuantizedLinear,tests the correctness of the quantized linear and linear relu op.,tests the correctness of the quantized linear and linear relu op.,,,,
6,TestYellowFin,"yellowfin an automatic tuner for momentum sgd
https arxiv.org abs 170603471",yellowfin an automatic tuner for momentum sgd,,,,
6,TransformerEncoderLayer,"transformerencoderlayer is made up of self attn and feedforward network.
this standard encoder layer is based on the paper attention is all you need .
ashish vaswani, noam shazeer, niki parmar, jakob uszkoreit, llion jones, aidan n gomez,
lukasz kaiser, and illia polosukhin. 2017. attention is all you need. in advances in
neural information processing systems, pages 6000 6010. users may modify or implement
in a different way during application.

args
d model the number of expected features in the input required .
nhead the number of heads in the multiheadattention models required .
dim feedforward the dimension of the feedforward network model default 2048 .
dropout the dropout value default 01 .
activation the activation function of intermediate layer, relu or gelu default relu .

examples
encoder layer nn.transformerencoderlayer d model 512, nhead 8
src torch.rand 10, 32, 512
out encoder layer src",,"examples
encoder layer nn.transformerencoderlayer d model 512, nhead 8
src torch.rand 10, 32, 512
out encoder layer src","args
d model the number of expected features in the input required .
nhead the number of heads in the multiheadattention models required .
dim feedforward the dimension of the feedforward network model default 2048 .
dropout the dropout value default 01 .
activation the activation function of intermediate layer, relu or gelu default relu .",,"transformerencoderlayer is made up of self attn and feedforward network.this standard encoder layer is based on the paper attention is all you need .
ashish vaswani, noam shazeer, niki parmar, jakob uszkoreit, llion jones, aidan n gomez,
lukasz kaiser, and illia polosukhin. 2017. attention is all you need. in advances in
neural information processing systems, pages 6000 6010. users may modify or implement
in a different way during application."
6,Unfold,"extracts sliding local blocks from a batched input tensor.

consider a batched attr input tensor of shape math n, c, ,
where math n is the batch dimension, math c is the channel dimension,
and math represent arbitrary spatial dimensions. this operation flattens
each sliding attr kernel size sized block within the spatial dimensions
of attr input into a column ie, last dimension of a 3 d attr output
tensor of shape math n, c times prod text kernel size , l , where
math c times prod text kernel size is the total number of values
within each block a block has math prod text kernel size spatial
locations each containing a math c channeled vector , and math l is
the total number of such blocks

math
l prod d left lfloor frac text spatial size d 2 times text padding d %
text dilation d times text kernel size d 1 1 text stride d 1 right rfloor,

where math text spatial size is formed by the spatial dimensions
of attr input math above , and math d is over all spatial
dimensions.

therefore, indexing attr output at the last dimension column dimension
gives all values within a certain block.

the attr padding , attr stride and attr dilation arguments specify
how the sliding blocks are retrieved.

attr stride controls the stride for the sliding blocks.

attr padding controls the amount of implicit zero paddings on both
sides for attr padding number of points for each dimension before
reshaping.

attr dilation controls the spacing between the kernel points also known as the trous algorithm.
it is harder to describe, but this link has a nice visualization of what attr dilation does.

args
kernel size int or tuple the size of the sliding blocks
stride int or tuple, optional the stride of the sliding blocks in the input
spatial dimensions. default 1
padding int or tuple, optional implicit zero padding to be added on
both sides of input. default 0
dilation int or tuple, optional a parameter that controls the
stride of elements within the
neighborhood. default 1

if attr kernel size , attr dilation , attr padding or
attr stride is an int or a tuple of length 1, their values will be
replicated across all spatial dimensions.

for the case of two input spatial dimensions this operation is sometimes
called im2col .

note
class torch.nn.fold calculates each combined value in the resulting
large tensor by summing all values from all containing blocks.
class torch.nn.unfold extracts the values in the local blocks by
copying from the large tensor. so, if the blocks overlap, they are not
inverses of each other.

in general, folding and unfolding operations are related as
follows. consider class torch.nn.fold and
class torch.nn.unfold instances created with the same
parameters

fold params dict kernel size ..., dilation ..., padding ..., stride ...
fold nn.fold output size ..., fold params
unfold nn.unfold fold params

then for any supported input tensor the following
equality holds

fold unfold input divisor input

where divisor is a tensor that depends only on the shape
and dtype of the input

input ones torch.ones input.shape, dtype input.dtype
divisor fold unfold input ones

when the divisor tensor contains no zero elements, then
fold and unfold operations are inverses of each
other up to constant divisor .

warning
currently, only 4 d input tensors batched image like tensors are
supported.

shape
input math n, c,
output math n, c times prod text kernel size , l as described above

examples

unfold nn.unfold kernel size 2, 3
input torch.randn 2, 5, 3, 4
output unfold input
# each patch contains 30 values 2x3 6 vectors, each of 5 channels
# 4 blocks 2x3 kernels in total in the 3x4 input
output.size
torch.size 2, 30, 4

# convolution is equivalent with unfold matrix multiplication fold or view to output shape
inp torch.randn 1, 3, 10, 12
w torch.randn 2, 3, 4, 5
inp unf torch.nn.functional.unfold inp, 4, 5
out unf inp unf.transpose 1, 2 .matmul w.view w.size 0 , 1 .t .transpose 1, 2
out torch.nn.functional.fold out unf, 7, 8 , 1, 1
# or equivalently and avoiding a copy ,
# out out unf.view 1, 2, 7, 8
torch.nn.functional.conv2d inp, w out .abs .max
tensor 19073e 06

link
https github.com vdumoulin conv arithmetic blob master readme.md",extracts sliding local blocks from a batched input tensor.,"consider a batched attr input tensor of shape math n, c, ,
where math n is the batch dimension, math c is the channel dimension,
and math represent arbitrary spatial dimensions. this operation flattens
each sliding attr kernel size sized block within the spatial dimensions
of attr input into a column ie, last dimension of a 3 d attr output
tensor of shape math n, c times prod text kernel size , l , where
math c times prod text kernel size is the total number of values
within each block a block has math prod text kernel size spatial
locations each containing a math c channeled vector , and math l is
the total number of such blocks

math
l prod d left lfloor frac text spatial size d 2 times text padding d %
text dilation d times text kernel size d 1 1 text stride d 1 right rfloor,

where math text spatial size is formed by the spatial dimensions
of attr input math above , and math d is over all spatial
dimensions.

therefore, indexing attr output at the last dimension column dimension
gives all values within a certain block.
examples

unfold nn.unfold kernel size 2, 3
input torch.randn 2, 5, 3, 4
output unfold input
# each patch contains 30 values 2x3 6 vectors, each of 5 channels
# 4 blocks 2x3 kernels in total in the 3x4 input
output.size
torch.size 2, 30, 4

# convolution is equivalent with unfold matrix multiplication fold or view to output shape
inp torch.randn 1, 3, 10, 12
w torch.randn 2, 3, 4, 5
inp unf torch.nn.functional.unfold inp, 4, 5
out unf inp unf.transpose 1, 2 .matmul w.view w.size 0 , 1 .t .transpose 1, 2
out torch.nn.functional.fold out unf, 7, 8 , 1, 1
# or equivalently and avoiding a copy ,
# out out unf.view 1, 2, 7, 8
torch.nn.functional.conv2d inp, w out .abs .max
tensor 19073e 06","the attr padding , attr stride and attr dilation arguments specify
how the sliding blocks are retrieved.

attr stride controls the stride for the sliding blocks.

attr padding controls the amount of implicit zero paddings on both
sides for attr padding number of points for each dimension before
reshaping.

attr dilation controls the spacing between the kernel points also known as the trous algorithm.
it is harder to describe, but this link has a nice visualization of what attr dilation does.

args
kernel size int or tuple the size of the sliding blocks
stride int or tuple, optional the stride of the sliding blocks in the input
spatial dimensions. default 1
padding int or tuple, optional implicit zero padding to be added on
both sides of input. default 0
dilation int or tuple, optional a parameter that controls the
stride of elements within the
neighborhood. default 1

if attr kernel size , attr dilation , attr padding or
attr stride is an int or a tuple of length 1, their values will be
replicated across all spatial dimensions.

for the case of two input spatial dimensions this operation is sometimes
called im2col .","consider a batched attr input tensor of shape math n, c, ,
where math n is the batch dimension, math c is the channel dimension,
and math represent arbitrary spatial dimensions. this operation flattens
each sliding attr kernel size sized block within the spatial dimensions
of attr input into a column ie, last dimension of a 3 d attr output
tensor of shape math n, c times prod text kernel size , l , where
math c times prod text kernel size is the total number of values
within each block a block has math prod text kernel size spatial
locations each containing a math c channeled vector , and math l is
the total number of such blocks

math
l prod d left lfloor frac text spatial size d 2 times text padding d %
text dilation d times text kernel size d 1 1 text stride d 1 right rfloor,

where math text spatial size is formed by the spatial dimensions
of attr input math above , and math d is over all spatial
dimensions.","note
class torch.nn.fold calculates each combined value in the resulting
large tensor by summing all values from all containing blocks.
class torch.nn.unfold extracts the values in the local blocks by
copying from the large tensor. so, if the blocks overlap, they are not
inverses of each other.

in general, folding and unfolding operations are related as
follows. consider class torch.nn.fold and
class torch.nn.unfold instances created with the same
parameters

fold params dict kernel size ..., dilation ..., padding ..., stride ...
fold nn.fold output size ..., fold params
unfold nn.unfold fold params

then for any supported input tensor the following
equality holds

fold unfold input divisor input

where divisor is a tensor that depends only on the shape
and dtype of the input

input ones torch.ones input.shape, dtype input.dtype
divisor fold unfold input ones

when the divisor tensor contains no zero elements, then
fold and unfold operations are inverses of each
other up to constant divisor ."
6,UploadTaskGroupBuilder,a simple class to upload checkpoints.,a simple class to upload checkpoints.,,,,
6,UseOptimizer,"context class to allow setting the current context.
example usage with brew
with useoptimizer optim
brew.func
with useoptimizer weight weight optim
brew.func
with useoptimizer default optim, bias bias optim,
weight weight optim
brew.func
with useoptimizer optim1
brew.func
with useoptimizer optim2
brew.func

example usage with layer
optimizers optim1 optim1, optim2 optim2
with optimizers optimizers
optim optimizercontext.current .get optimizer optim1
layer optim optim",context class to allow setting the current context.,"example usage with brew
with useoptimizer optim
brew.func
with useoptimizer weight weight optim
brew.func
with useoptimizer default optim, bias bias optim,
weight weight optim
brew.func
with useoptimizer optim1
brew.func
with useoptimizer optim2
brew.func",,,
6,YellowFinOptimizer,"yellowfin an automatic tuner for momentum sgd

see https arxiv.org abs 170603471 for more details. this implementation
has separate learning rate and momentum per each parameter.",yellowfin an automatic tuner for momentum sgd,,,,this implementation has separate learning rate and momentum per each parameter.
7,AuthBase,base class that all auth implementations derive from,base class that all auth implementations derive from,,,,
7,InvalidHeader,the header value provided was somehow invalid.,the header value provided was somehow invalid.,,,,
7,PreparedRequest,"the fully mutable class preparedrequest preparedrequest object,
containing the exact bytes that will be sent to the server.

generated from either a class request request object or manually.

usage

import requests
req requests.request get , https httpbin.org get
r req.prepare
r
preparedrequest get

s requests.session
s.send r
response 200","the fully mutable class preparedrequest preparedrequest object,
containing the exact bytes that will be sent to the server.","usage

import requests
req requests.request get , https httpbin.org get
r req.prepare
r
preparedrequest get

s requests.session
s.send r
response 200",,,generated from either a class request request object or manually.
7,Response,"the class response response object, which contains a
server s response to an http request.","the class response response object, which contains a
server s response to an http request.",,,,
